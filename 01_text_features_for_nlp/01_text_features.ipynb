{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01.Text Vectorization (Draft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 차례\n",
    "* Frequency Vectors\n",
    "* One-Hot Encoding\n",
    "* Term Frequency-Inverse Document Frequency\n",
    "* Distributed Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nbviewer.jupyter.org/github/psygrammer/psyml/blob/master/nlp_ml/ch01/figures/cap1.3.png\" width=600 />\n",
    "<img src=\"https://nbviewer.jupyter.org/github/psygrammer/psyml/blob/master/nlp_ml/ch01/figures/cap1.4.png\" width=600 />\n",
    "\n",
    "* 출처 - Applied Text Analysis with Python: Enabling Language-Aware Data Products with Machine Learning - https://www.amazon.com/Applied-Text-Analysis-Python-Language-Aware/dp/1491963042/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/main_nlp_01.png\" width=600 />\n",
    "<img src=\"figures/main_nlp_02.png\" width=600 />\n",
    "<img src=\"figures/main_nlp_03.png\" width=600 />\n",
    "<img src=\"figures/main_nlp_04.png\" width=600 />\n",
    "<img src=\"figures/main_nlp_05.png\" width=600 />\n",
    "\n",
    "* 출처 - Natural Language Processing - https://www.coursera.org/learn/language-processing - Main approaches in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nbviewer.jupyter.org/github/psygrammer/psyml/blob/master/nlp_ml/ch04/figures/cap01.png\" width=600 />\n",
    "\n",
    "* 출처 - Applied Text Analysis with Python: Enabling Language-Aware Data Products with Machine Learning - https://www.amazon.com/Applied-Text-Analysis-Python-Language-Aware/dp/1491963042/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://slideplayer.com/slide/5270778/17/images/10/Distributed+Word+Representation.jpg\" width=600 />\n",
    "\n",
    "* 출처 - https://slideplayer.com/slide/5270778/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nbviewer.jupyter.org/github/psygrammer/psyml/blob/master/nlp_ml/ch04/figures/cap02.png\" width=600 />\n",
    "\n",
    "* 출처 - Applied Text Analysis with Python: Enabling Language-Aware Data Products with Machine Learning - https://www.amazon.com/Applied-Text-Analysis-Python-Language-Aware/dp/1491963042/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim을 이용하려면 문서 목록인 documents를 corpus 클래스로 바꿔야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가상의 문서 4개\n",
    "documents = [\n",
    "    \"a b c a\",\n",
    "    \"c b c\",\n",
    "    \"b b a\",\n",
    "    \"a c c\",\n",
    "    \"c b a\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'b', 'c', 'a'],\n",
      " ['c', 'b', 'c'],\n",
      " ['b', 'b', 'a'],\n",
      " ['a', 'c', 'c'],\n",
      " ['c', 'b', 'a']]\n"
     ]
    }
   ],
   "source": [
    "# 단어(토큰) 단위로 분할\n",
    "def tokenize(x) :\n",
    "    for token in x.split() :\n",
    "        yield token\n",
    "        \n",
    "corpus = [list(tokenize(doc)) for doc in  documents]\n",
    "\n",
    "pprint(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary 객체. 구체적으로는 단어에 id 할당 (그 외에도 여러가지 기능은 튜토리얼 참조)\n",
    "id2word = gensim.corpora.Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x1a174cd198>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1, 'c': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [id2word.doc2bow(doc) for doc in corpus]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 2), (1, 1), (2, 1)],\n",
      " [(1, 1), (2, 2)],\n",
      " [(0, 1), (1, 2)],\n",
      " [(0, 1), (2, 2)],\n",
      " [(0, 1), (1, 1), (2, 1)]]\n"
     ]
    }
   ],
   "source": [
    "pprint(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nbviewer.jupyter.org/github/psygrammer/psyml/blob/master/nlp_ml/ch04/figures/cap03.png\" width=600 />\n",
    "\n",
    "* 출처 - Applied Text Analysis with Python: Enabling Language-Aware Data Products with Machine Learning - https://www.amazon.com/Applied-Text-Analysis-Python-Language-Aware/dp/1491963042/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'b', 'c', 'a'],\n",
       " ['c', 'b', 'c'],\n",
       " ['b', 'b', 'a'],\n",
       " ['a', 'c', 'c'],\n",
       " ['c', 'b', 'a']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 2), (1, 1), (2, 1)],\n",
       " [(1, 1), (2, 2)],\n",
       " [(0, 1), (1, 2)],\n",
       " [(0, 1), (2, 2)],\n",
       " [(0, 1), (1, 1), (2, 1)]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2word.doc2bow(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 2), (1, 1), (2, 1)],\n",
       " [(1, 1), (2, 2)],\n",
       " [(0, 1), (1, 2)],\n",
       " [(0, 1), (2, 2)],\n",
       " [(0, 1), (1, 1), (2, 1)]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[token for token in id2word.doc2bow(doc)] \n",
    "                         for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 2), (1, 1), (2, 1)],\n",
       " [(1, 1), (2, 2)],\n",
       " [(0, 1), (1, 2)],\n",
       " [(0, 1), (2, 2)],\n",
       " [(0, 1), (1, 1), (2, 1)]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(token[0], token[1]) for token in id2word.doc2bow(doc)] \n",
    "                         for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [[(token[0], 1) for token in id2word.doc2bow(doc)] \n",
    "                         for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors  = np.array([\n",
    "        [(token[0], 1) for token in id2word.doc2bow(doc)]\n",
    "        for doc in corpus\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1)],\n",
       " [(0, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency-Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nbviewer.jupyter.org/github/psygrammer/psyml/blob/master/nlp_ml/ch04/figures/cap04.png\" width=600 />\n",
    "\n",
    "* 출처 - Applied Text Analysis with Python: Enabling Language-Aware Data Products with Machine Learning - https://www.amazon.com/Applied-Text-Analysis-Python-Language-Aware/dp/1491963042/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c a', 'c b c', 'b b a', 'a c c', 'c b a']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'b', 'c', 'a'],\n",
       " ['c', 'b', 'c'],\n",
       " ['b', 'b', 'a'],\n",
       " ['a', 'c', 'c'],\n",
       " ['c', 'b', 'a']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary 생성\n",
    "id2word = gensim.corpora.Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.tfidfmodel.TfidfModel at 0x1a174d4940>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tfidf Model 생성\n",
    "tfidf = gensim.models.TfidfModel(dictionary=id2word, normalize=True)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.816496580927726), (1, 0.408248290463863), (2, 0.408248290463863)],\n",
       " [(1, 0.447213595499958), (2, 0.894427190999916)],\n",
       " [(0, 0.447213595499958), (1, 0.894427190999916)],\n",
       " [(0, 0.447213595499958), (2, 0.894427190999916)],\n",
       " [(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = [tfidf[id2word.doc2bow(vector)] for vector in corpus]\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary와 tfidf model을 저장해 놓으면 나중에 다시 로드해서 쓸 수 있어 편하다. \n",
    "id2word.save_as_text('test.txt')\n",
    "tfidf.save('tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_text_features.ipynb  test.txt\r\n",
      "\u001b[34mfigures\u001b[m\u001b[m/                tfidf.pkl\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 한국어 예제 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 출처 - 나만의 웹 크롤러 만들기 with Requests/BeautifulSoup - https://beomi.github.io/2017/01/20/HowToMakeWebCrawler/\n",
    "* 출처 - https://www.slideshare.net/kimhyunjoonglovit/pycon2017-koreannlp\n",
    "* 출처 - https://github.com/lovit/soynlp/blob/master/tutorials/nounextractor-v2_usage.ipynb\n",
    "* 출처 - https://wikidocs.net/24603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://gasazip.com/view.html?no=614736\"\n",
    "#url = \"https://gasazip.com/view.html?no=636135\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTTP GET Request\n",
    "req = requests.get(url)\n",
    "# HTML 소스 가져오기\n",
    "html = req.text\n",
    "# BeautifulSoup으로 html소스를 python객체로 변환하기\n",
    "# 첫 인자는 html소스코드, 두 번째 인자는 어떤 parser를 이용할지 명시.\n",
    "# 여기서는 Python 내장 html.parser를 이용했다.\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = []\n",
    "for txt in soup.find_all('div', attrs={'class': 'col-md-8'}) :\n",
    "    lines = txt.get_text().split('\\n')\n",
    "    for line in lines :\n",
    "        lyrics.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHEER UP',\n",
       " '',\n",
       " '매일 울리는 벨벨벨',\n",
       " '이젠 나를 배려 해줘',\n",
       " '배터리 낭비하긴 싫어',\n",
       " '자꾸만 봐 자꾸 자꾸만 와',\n",
       " '전화가 펑 터질 것만 같아',\n",
       " '몰라 몰라 숨도 못 쉰대',\n",
       " '나 때문에 힘들어',\n",
       " '쿵 심장이 떨어진대 왜',\n",
       " '걔 말은 나 너무 예쁘대',\n",
       " '자랑 하는건 아니구',\n",
       " '아 아까는 못 받아서 미안해',\n",
       " '친구를 만나느라 shy shy shy',\n",
       " '만나긴 좀 그렇구 미안해',\n",
       " '좀 있다 연락할게 later',\n",
       " '조르지마 얼마 가지 않아',\n",
       " '부르게 해줄게 Baby',\n",
       " '아직은 좀 일러 내 맘 같긴 일러',\n",
       " '하지만 더 보여줄래',\n",
       " 'CHEER UP BABY CHEER UP BABY',\n",
       " '좀 더 힘을 내',\n",
       " '여자가 쉽게 맘을 주면 안돼',\n",
       " '그래야 니가 날 더 좋아하게 될걸',\n",
       " '태연하게 연기할래 아무렇지 않게',\n",
       " '내가 널 좋아하는 맘 모르게',\n",
       " 'just get it together',\n",
       " 'and then baby CHEER UP',\n",
       " '안절부절 목소리가',\n",
       " '여기까지 들려',\n",
       " '땀에 젖은 전화기가',\n",
       " '여기서도 보여',\n",
       " '바로 바로 대답하는 것도',\n",
       " '매력 없어',\n",
       " '메시지만 읽고',\n",
       " '확인 안 하는 건 기본',\n",
       " '어어어 너무 심했나 boy',\n",
       " '이러다가 지칠까 봐',\n",
       " '걱정되긴 하고',\n",
       " '어어어 안 그러면 내가 더',\n",
       " '빠질 것만 같어 빠질 것만 같어',\n",
       " '아 답장을 못해줘서 미안해',\n",
       " '친구를 만나느라 shy shy shy',\n",
       " '만나긴 좀 그렇구 미안해',\n",
       " '좀 있다 연락할게 later',\n",
       " '조르지마 어디 가지 않아',\n",
       " '되어줄게 너의 Baby',\n",
       " '너무 빨린 싫어 성의를 더 보여',\n",
       " '내가 널 기다려줄게',\n",
       " 'CHEER UP BABY CHEER UP BABY',\n",
       " '좀 더 힘을 내',\n",
       " '여자가 쉽게 맘을 주면 안돼',\n",
       " '그래야 니가 날 더 좋아하게 될걸',\n",
       " '태연하게 연기할래 아무렇지 않게',\n",
       " '내가 널 좋아하는 맘 모르게',\n",
       " 'just get it together',\n",
       " 'and then baby CHEER UP',\n",
       " '나도 니가 좋아 상처 입을까 봐',\n",
       " '걱정되지만 여자니까 이해해주길',\n",
       " '속 마음 들킬 까봐 겁이나',\n",
       " '지금처럼 조금만 더 다가와',\n",
       " '그리 오래 걸리진 않아',\n",
       " 'just get it together',\n",
       " 'and then baby CHEER UP',\n",
       " 'Be a man a real man',\n",
       " 'gotta see u love me like a real man',\n",
       " 'Be a man a real man',\n",
       " 'gotta see u love me like a real man',\n",
       " 'CHEER UP BABY CHEER UP BABY',\n",
       " '좀 더 힘을 내',\n",
       " '여자가 쉽게 맘을 주면 안돼',\n",
       " '그래야 니가 날 더 좋아하게 될걸',\n",
       " '태연하게 연기할래 아무렇지 않게',\n",
       " '내가 널 좋아하는 맘 모르게',\n",
       " 'just get it together',\n",
       " 'and then baby CHEER UP',\n",
       " '',\n",
       " 'HTTP://K2NBLOG.COM',\n",
       " '']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'매일 울리는 벨벨벨'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 문장을 좀 형태소 분석을 이용해서 정리하고 싶다.\n",
    "sent = lyrics[2]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] use default predictors\n",
      "[Noun Extractor] num features: pos=1260, neg=1173, common=12\n"
     ]
    }
   ],
   "source": [
    "from soynlp.noun import LRNounExtractor_v2\n",
    "\n",
    "noun_extractor = LRNounExtractor_v2(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] counting eojeols\n",
      "[EojeolCounter] n eojeol = 162 from 79 sents. mem=0.113 Gb                    \n",
      "[Noun Extractor] complete eojeol counter -> lr graph\n",
      "[Noun Extractor] has been trained. #eojeols=331, mem=0.113 Gb\n",
      "[Noun Extractor] batch prediction was completed for 48 words\n",
      "[Noun Extractor] checked compounds. discovered 0 compounds\n",
      "[Noun Extractor] postprocessing detaching_features : 11 -> 11\n",
      "[Noun Extractor] postprocessing ignore_features : 11 -> 10\n",
      "[Noun Extractor] postprocessing ignore_NJ : 10 -> 10\n",
      "[Noun Extractor] 10 nouns (0 compounds) with min frequency=1\n",
      "[Noun Extractor] flushing was done. mem=0.113 Gb                    \n",
      "[Noun Extractor] 13.60 % eojeols are covered\n"
     ]
    }
   ],
   "source": [
    "# 학습기반 단어 추출기\n",
    "nouns = noun_extractor.train_extract(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'여자': NounScore(frequency=3, score=1.0),\n",
       " '여기': NounScore(frequency=1, score=1.0),\n",
       " '자꾸': NounScore(frequency=3, score=1.0),\n",
       " '좋아': NounScore(frequency=4, score=1.0),\n",
       " '내': NounScore(frequency=9, score=1.0),\n",
       " '안': NounScore(frequency=5, score=0.8333333333333334),\n",
       " '것': NounScore(frequency=4, score=1.0),\n",
       " '힘': NounScore(frequency=3, score=0.75),\n",
       " '맘': NounScore(frequency=7, score=1.0),\n",
       " '심': NounScore(frequency=1, score=0.5)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.tokenizer import MaxScoreTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'여자': 1.0,\n",
       " '여기': 1.0,\n",
       " '자꾸': 1.0,\n",
       " '좋아': 1.0,\n",
       " '내': 1.0,\n",
       " '안': 0.8333333333333334,\n",
       " '것': 1.0,\n",
       " '힘': 0.75,\n",
       " '맘': 1.0,\n",
       " '심': 0.5}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {w:s.score for w, s in nouns.items()}\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MaxScoreTokenizer(scores=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHEER UP\n",
      "['CHEER', 'UP']\n",
      "\n",
      "[]\n",
      "매일 울리는 벨벨벨\n",
      "['매일', '울리는', '벨벨벨']\n",
      "이젠 나를 배려 해줘\n",
      "['이젠', '나를', '배려', '해줘']\n",
      "배터리 낭비하긴 싫어\n",
      "['배터리', '낭비하긴', '싫어']\n",
      "자꾸만 봐 자꾸 자꾸만 와\n",
      "['자꾸', '만', '봐', '자꾸', '자꾸', '만', '와']\n",
      "전화가 펑 터질 것만 같아\n",
      "['전화가', '펑', '터질', '것만', '같아']\n",
      "몰라 몰라 숨도 못 쉰대\n",
      "['몰라', '몰라', '숨도', '못', '쉰대']\n",
      "나 때문에 힘들어\n",
      "['나', '때문에', '힘들어']\n",
      "쿵 심장이 떨어진대 왜\n",
      "['쿵', '심장이', '떨어진대', '왜']\n"
     ]
    }
   ],
   "source": [
    "for sent in lyrics[:10] :\n",
    "    print(sent)\n",
    "    tokens = tokenizer.tokenize(sent)\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['CHEER', 'UP'],\n",
      " [],\n",
      " ['매일', '울리는', '벨벨벨'],\n",
      " ['이젠', '나를', '배려', '해줘'],\n",
      " ['배터리', '낭비하긴', '싫어'],\n",
      " ['자꾸', '만', '봐', '자꾸', '자꾸', '만', '와'],\n",
      " ['전화가', '펑', '터질', '것만', '같아'],\n",
      " ['몰라', '몰라', '숨도', '못', '쉰대'],\n",
      " ['나', '때문에', '힘들어'],\n",
      " ['쿵', '심장이', '떨어진대', '왜'],\n",
      " ['걔', '말은', '나', '너무', '예쁘대'],\n",
      " ['자랑', '하는건', '아니구'],\n",
      " ['아', '아까는', '못', '받아서', '미안해'],\n",
      " ['친구를', '만나느라', 'shy', 'shy', 'shy'],\n",
      " ['만나긴', '좀', '그렇구', '미안해'],\n",
      " ['좀', '있다', '연락할게', 'later'],\n",
      " ['조르지마', '얼마', '가지', '않아'],\n",
      " ['부르게', '해줄게', 'Baby'],\n",
      " ['아직은', '좀', '일러', '내', '맘', '같긴', '일러'],\n",
      " ['하지만', '더', '보여줄래'],\n",
      " ['CHEER', 'UP', 'BABY', 'CHEER', 'UP', 'BABY'],\n",
      " ['좀', '더', '힘을', '내'],\n",
      " ['여자', '가', '쉽게', '맘을', '주면', '안돼'],\n",
      " ['그래야', '니가', '날', '더', '좋아', '하게', '될걸'],\n",
      " ['태연하게', '연기할래', '아무렇지', '않게'],\n",
      " ['내가', '널', '좋아', '하는', '맘', '모르게'],\n",
      " ['just', 'get', 'it', 'together'],\n",
      " ['and', 'then', 'baby', 'CHEER', 'UP'],\n",
      " ['안절부절', '목소리가'],\n",
      " ['여기', '까지', '들려'],\n",
      " ['땀에', '젖은', '전화기가'],\n",
      " ['여기', '서도', '보여'],\n",
      " ['바로', '바로', '대답하는', '것도'],\n",
      " ['매력', '없어'],\n",
      " ['메시지만', '읽고'],\n",
      " ['확인', '안', '하는', '건', '기본'],\n",
      " ['어어어', '너무', '심했나', 'boy'],\n",
      " ['이러다가', '지칠까', '봐'],\n",
      " ['걱정되긴', '하고'],\n",
      " ['어어어', '안', '그러면', '내가', '더'],\n",
      " ['빠질', '것만', '같어', '빠질', '것만', '같어'],\n",
      " ['아', '답장을', '못해줘서', '미안해'],\n",
      " ['친구를', '만나느라', 'shy', 'shy', 'shy'],\n",
      " ['만나긴', '좀', '그렇구', '미안해'],\n",
      " ['좀', '있다', '연락할게', 'later'],\n",
      " ['조르지마', '어디', '가지', '않아'],\n",
      " ['되어줄게', '너의', 'Baby'],\n",
      " ['너무', '빨린', '싫어', '성의를', '더', '보여'],\n",
      " ['내가', '널', '기다려줄게'],\n",
      " ['CHEER', 'UP', 'BABY', 'CHEER', 'UP', 'BABY'],\n",
      " ['좀', '더', '힘을', '내'],\n",
      " ['여자', '가', '쉽게', '맘을', '주면', '안돼'],\n",
      " ['그래야', '니가', '날', '더', '좋아', '하게', '될걸'],\n",
      " ['태연하게', '연기할래', '아무렇지', '않게'],\n",
      " ['내가', '널', '좋아', '하는', '맘', '모르게'],\n",
      " ['just', 'get', 'it', 'together'],\n",
      " ['and', 'then', 'baby', 'CHEER', 'UP'],\n",
      " ['나도', '니가', '좋아', '상처', '입을까', '봐'],\n",
      " ['걱정되지만', '여자', '니까', '이해해주길'],\n",
      " ['속', '마음', '들킬', '까봐', '겁이나'],\n",
      " ['지금처럼', '조금만', '더', '다가와'],\n",
      " ['그리', '오래', '걸리진', '않아'],\n",
      " ['just', 'get', 'it', 'together'],\n",
      " ['and', 'then', 'baby', 'CHEER', 'UP'],\n",
      " ['Be', 'a', 'man', 'a', 'real', 'man'],\n",
      " ['gotta', 'see', 'u', 'love', 'me', 'like', 'a', 'real', 'man'],\n",
      " ['Be', 'a', 'man', 'a', 'real', 'man'],\n",
      " ['gotta', 'see', 'u', 'love', 'me', 'like', 'a', 'real', 'man'],\n",
      " ['CHEER', 'UP', 'BABY', 'CHEER', 'UP', 'BABY'],\n",
      " ['좀', '더', '힘을', '내'],\n",
      " ['여자', '가', '쉽게', '맘을', '주면', '안돼'],\n",
      " ['그래야', '니가', '날', '더', '좋아', '하게', '될걸'],\n",
      " ['태연하게', '연기할래', '아무렇지', '않게'],\n",
      " ['내가', '널', '좋아', '하는', '맘', '모르게'],\n",
      " ['just', 'get', 'it', 'together'],\n",
      " ['and', 'then', 'baby', 'CHEER', 'UP'],\n",
      " [],\n",
      " ['HTTP://K2N', 'BLOG.COM'],\n",
      " []]\n"
     ]
    }
   ],
   "source": [
    "# 단어(토큰) 단위로 분할하는 함수\n",
    "def tokenize(x, tokenizer) :\n",
    "    for token in tokenizer.tokenize(x) :\n",
    "        yield token\n",
    "        \n",
    "# 코퍼스를 만들자\n",
    "corpus = [list(tokenize(sent, tokenizer)) for sent in lyrics]\n",
    "\n",
    "pprint(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary 생성\n",
    "dictionary = gensim.corpora.Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tfidf Model 생성\n",
    "tfidf = gensim.models.TfidfModel(dictionary=dictionary, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.7071067811865475), (1, 0.7071067811865475)],\n",
       " [],\n",
       " [(2, 0.5773502691896257), (3, 0.5773502691896257), (4, 0.5773502691896257)],\n",
       " [(5, 0.5), (6, 0.5), (7, 0.5), (8, 0.5)],\n",
       " [(9, 0.6076927837595194), (10, 0.6076927837595194), (11, 0.5112914639745239)],\n",
       " [(12, 0.5241360043138908),\n",
       "  (13, 0.1961761235128819),\n",
       "  (14, 0.2620680021569454),\n",
       "  (15, 0.7862040064708362)],\n",
       " [(16, 0.4608786708968913),\n",
       "  (17, 0.3877672018740884),\n",
       "  (18, 0.4608786708968913),\n",
       "  (19, 0.4608786708968913),\n",
       "  (20, 0.4608786708968913)],\n",
       " [(21, 0.7722125641071458),\n",
       "  (22, 0.3248563278629508),\n",
       "  (23, 0.3861062820535729),\n",
       "  (24, 0.3861062820535729)],\n",
       " [(25, 0.5112914639745239),\n",
       "  (26, 0.6076927837595194),\n",
       "  (27, 0.6076927837595194)],\n",
       " [(28, 0.5), (29, 0.5), (30, 0.5), (31, 0.5)]]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = [tfidf[dictionary.doc2bow(vector)] for vector in corpus]\n",
    "vectors[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf 기반 벡터 유사도 \n",
    "from gensim import similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a, b, dic) :\n",
    "    index = similarities.MatrixSimilarity([a],num_features=len(dic))\n",
    "    sim = index[b]\n",
    "    return sim[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  ['CHEER', 'UP']\n",
      "[(0, 0.7071067811865475), (1, 0.7071067811865475)]\n",
      "B:  ['이젠', '나를', '배려', '해줘']\n",
      "[(5, 0.5), (6, 0.5), (7, 0.5), (8, 0.5)]\n",
      "0.0 % similar\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "print(\"A: \", corpus[a])\n",
    "print(vectors[a])\n",
    "\n",
    "b = 3\n",
    "print(\"B: \", corpus[b])\n",
    "print(vectors[b])\n",
    "\n",
    "sim = distance(vectors[a], vectors[b], dictionary)\n",
    "\n",
    "print(round(sim,2),'% similar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  ['이젠', '나를', '배려', '해줘']\n",
      "[(5, 0.5), (6, 0.5), (7, 0.5), (8, 0.5)]\n",
      "B:  ['이젠', '나를', '배려', '해줘']\n",
      "[(5, 0.5), (6, 0.5), (7, 0.5), (8, 0.5)]\n",
      "100.0 % similar\n"
     ]
    }
   ],
   "source": [
    "a = 3\n",
    "print(\"A: \", corpus[a])\n",
    "print(vectors[a])\n",
    "\n",
    "b = 3\n",
    "print(\"B: \", corpus[b])\n",
    "print(vectors[b])\n",
    "\n",
    "sim = distance(vectors[a], vectors[b], dictionary)\n",
    "\n",
    "print(round(sim,2),'% similar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  ['자꾸', '만', '봐', '자꾸', '자꾸', '만', '와']\n",
      "[(12, 0.5241360043138908), (13, 0.1961761235128819), (14, 0.2620680021569454), (15, 0.7862040064708362)]\n",
      "B:  ['내가', '널', '좋아', '하는', '맘', '모르게']\n",
      "[(61, 0.418187890302657), (79, 0.3397391794282149), (85, 0.3869069216131805), (86, 0.418187890302657), (87, 0.4585160729809741), (88, 0.418187890302657)]\n",
      "0.0 % similar\n"
     ]
    }
   ],
   "source": [
    "a = 5\n",
    "print(\"A: \", corpus[a])\n",
    "print(vectors[a])\n",
    "\n",
    "b = 25\n",
    "print(\"B: \", corpus[b])\n",
    "print(vectors[b])\n",
    "\n",
    "sim = distance(vectors[a], vectors[b], dictionary)\n",
    "\n",
    "print(round(sim,2),'% similar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Document Embedding\n",
    "    - Doc2Vec\n",
    "* Word Embedding\n",
    "    - Word2Vec\n",
    "    - Glove\n",
    "    - FastText\n",
    "* Sentence Embeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nbviewer.jupyter.org/github/psygrammer/psyml/blob/master/nlp_ml/ch04/figures/cap05.png\" width=600 />\n",
    "\n",
    "* 출처 - Applied Text Analysis with Python: Enabling Language-Aware Data Products with Machine Learning - https://www.amazon.com/Applied-Text-Analysis-Python-Language-Aware/dp/1491963042/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Embedding\n",
    "* Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CHEER', 'UP'],\n",
       " [],\n",
       " ['매일', '울리는', '벨벨벨'],\n",
       " ['이젠', '나를', '배려', '해줘'],\n",
       " ['배터리', '낭비하긴', '싫어'],\n",
       " ['자꾸', '만', '봐', '자꾸', '자꾸', '만', '와'],\n",
       " ['전화가', '펑', '터질', '것만', '같아'],\n",
       " ['몰라', '몰라', '숨도', '못', '쉰대'],\n",
       " ['나', '때문에', '힘들어'],\n",
       " ['쿵', '심장이', '떨어진대', '왜'],\n",
       " ['걔', '말은', '나', '너무', '예쁘대'],\n",
       " ['자랑', '하는건', '아니구'],\n",
       " ['아', '아까는', '못', '받아서', '미안해'],\n",
       " ['친구를', '만나느라', 'shy', 'shy', 'shy'],\n",
       " ['만나긴', '좀', '그렇구', '미안해'],\n",
       " ['좀', '있다', '연락할게', 'later'],\n",
       " ['조르지마', '얼마', '가지', '않아'],\n",
       " ['부르게', '해줄게', 'Baby'],\n",
       " ['아직은', '좀', '일러', '내', '맘', '같긴', '일러'],\n",
       " ['하지만', '더', '보여줄래'],\n",
       " ['CHEER', 'UP', 'BABY', 'CHEER', 'UP', 'BABY'],\n",
       " ['좀', '더', '힘을', '내'],\n",
       " ['여자', '가', '쉽게', '맘을', '주면', '안돼'],\n",
       " ['그래야', '니가', '날', '더', '좋아', '하게', '될걸'],\n",
       " ['태연하게', '연기할래', '아무렇지', '않게'],\n",
       " ['내가', '널', '좋아', '하는', '맘', '모르게'],\n",
       " ['just', 'get', 'it', 'together'],\n",
       " ['and', 'then', 'baby', 'CHEER', 'UP'],\n",
       " ['안절부절', '목소리가'],\n",
       " ['여기', '까지', '들려'],\n",
       " ['땀에', '젖은', '전화기가'],\n",
       " ['여기', '서도', '보여'],\n",
       " ['바로', '바로', '대답하는', '것도'],\n",
       " ['매력', '없어'],\n",
       " ['메시지만', '읽고'],\n",
       " ['확인', '안', '하는', '건', '기본'],\n",
       " ['어어어', '너무', '심했나', 'boy'],\n",
       " ['이러다가', '지칠까', '봐'],\n",
       " ['걱정되긴', '하고'],\n",
       " ['어어어', '안', '그러면', '내가', '더'],\n",
       " ['빠질', '것만', '같어', '빠질', '것만', '같어'],\n",
       " ['아', '답장을', '못해줘서', '미안해'],\n",
       " ['친구를', '만나느라', 'shy', 'shy', 'shy'],\n",
       " ['만나긴', '좀', '그렇구', '미안해'],\n",
       " ['좀', '있다', '연락할게', 'later'],\n",
       " ['조르지마', '어디', '가지', '않아'],\n",
       " ['되어줄게', '너의', 'Baby'],\n",
       " ['너무', '빨린', '싫어', '성의를', '더', '보여'],\n",
       " ['내가', '널', '기다려줄게'],\n",
       " ['CHEER', 'UP', 'BABY', 'CHEER', 'UP', 'BABY'],\n",
       " ['좀', '더', '힘을', '내'],\n",
       " ['여자', '가', '쉽게', '맘을', '주면', '안돼'],\n",
       " ['그래야', '니가', '날', '더', '좋아', '하게', '될걸'],\n",
       " ['태연하게', '연기할래', '아무렇지', '않게'],\n",
       " ['내가', '널', '좋아', '하는', '맘', '모르게'],\n",
       " ['just', 'get', 'it', 'together'],\n",
       " ['and', 'then', 'baby', 'CHEER', 'UP'],\n",
       " ['나도', '니가', '좋아', '상처', '입을까', '봐'],\n",
       " ['걱정되지만', '여자', '니까', '이해해주길'],\n",
       " ['속', '마음', '들킬', '까봐', '겁이나'],\n",
       " ['지금처럼', '조금만', '더', '다가와'],\n",
       " ['그리', '오래', '걸리진', '않아'],\n",
       " ['just', 'get', 'it', 'together'],\n",
       " ['and', 'then', 'baby', 'CHEER', 'UP'],\n",
       " ['Be', 'a', 'man', 'a', 'real', 'man'],\n",
       " ['gotta', 'see', 'u', 'love', 'me', 'like', 'a', 'real', 'man'],\n",
       " ['Be', 'a', 'man', 'a', 'real', 'man'],\n",
       " ['gotta', 'see', 'u', 'love', 'me', 'like', 'a', 'real', 'man'],\n",
       " ['CHEER', 'UP', 'BABY', 'CHEER', 'UP', 'BABY'],\n",
       " ['좀', '더', '힘을', '내'],\n",
       " ['여자', '가', '쉽게', '맘을', '주면', '안돼'],\n",
       " ['그래야', '니가', '날', '더', '좋아', '하게', '될걸'],\n",
       " ['태연하게', '연기할래', '아무렇지', '않게'],\n",
       " ['내가', '널', '좋아', '하는', '맘', '모르게'],\n",
       " ['just', 'get', 'it', 'together'],\n",
       " ['and', 'then', 'baby', 'CHEER', 'UP'],\n",
       " [],\n",
       " ['HTTP://K2N', 'BLOG.COM'],\n",
       " []]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs   = [ \n",
    "    TaggedDocument(words, ['d{}'.format(idx)])\n",
    "        for idx, words in enumerate(corpus)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['CHEER', 'UP'], tags=['d0']),\n",
       " TaggedDocument(words=[], tags=['d1']),\n",
       " TaggedDocument(words=['매일', '울리는', '벨벨벨'], tags=['d2']),\n",
       " TaggedDocument(words=['이젠', '나를', '배려', '해줘'], tags=['d3']),\n",
       " TaggedDocument(words=['배터리', '낭비하긴', '싫어'], tags=['d4']),\n",
       " TaggedDocument(words=['자꾸', '만', '봐', '자꾸', '자꾸', '만', '와'], tags=['d5']),\n",
       " TaggedDocument(words=['전화가', '펑', '터질', '것만', '같아'], tags=['d6']),\n",
       " TaggedDocument(words=['몰라', '몰라', '숨도', '못', '쉰대'], tags=['d7']),\n",
       " TaggedDocument(words=['나', '때문에', '힘들어'], tags=['d8']),\n",
       " TaggedDocument(words=['쿵', '심장이', '떨어진대', '왜'], tags=['d9']),\n",
       " TaggedDocument(words=['걔', '말은', '나', '너무', '예쁘대'], tags=['d10']),\n",
       " TaggedDocument(words=['자랑', '하는건', '아니구'], tags=['d11']),\n",
       " TaggedDocument(words=['아', '아까는', '못', '받아서', '미안해'], tags=['d12']),\n",
       " TaggedDocument(words=['친구를', '만나느라', 'shy', 'shy', 'shy'], tags=['d13']),\n",
       " TaggedDocument(words=['만나긴', '좀', '그렇구', '미안해'], tags=['d14']),\n",
       " TaggedDocument(words=['좀', '있다', '연락할게', 'later'], tags=['d15']),\n",
       " TaggedDocument(words=['조르지마', '얼마', '가지', '않아'], tags=['d16']),\n",
       " TaggedDocument(words=['부르게', '해줄게', 'Baby'], tags=['d17']),\n",
       " TaggedDocument(words=['아직은', '좀', '일러', '내', '맘', '같긴', '일러'], tags=['d18']),\n",
       " TaggedDocument(words=['하지만', '더', '보여줄래'], tags=['d19']),\n",
       " TaggedDocument(words=['CHEER', 'UP', 'BABY', 'CHEER', 'UP', 'BABY'], tags=['d20']),\n",
       " TaggedDocument(words=['좀', '더', '힘을', '내'], tags=['d21']),\n",
       " TaggedDocument(words=['여자', '가', '쉽게', '맘을', '주면', '안돼'], tags=['d22']),\n",
       " TaggedDocument(words=['그래야', '니가', '날', '더', '좋아', '하게', '될걸'], tags=['d23']),\n",
       " TaggedDocument(words=['태연하게', '연기할래', '아무렇지', '않게'], tags=['d24']),\n",
       " TaggedDocument(words=['내가', '널', '좋아', '하는', '맘', '모르게'], tags=['d25']),\n",
       " TaggedDocument(words=['just', 'get', 'it', 'together'], tags=['d26']),\n",
       " TaggedDocument(words=['and', 'then', 'baby', 'CHEER', 'UP'], tags=['d27']),\n",
       " TaggedDocument(words=['안절부절', '목소리가'], tags=['d28']),\n",
       " TaggedDocument(words=['여기', '까지', '들려'], tags=['d29']),\n",
       " TaggedDocument(words=['땀에', '젖은', '전화기가'], tags=['d30']),\n",
       " TaggedDocument(words=['여기', '서도', '보여'], tags=['d31']),\n",
       " TaggedDocument(words=['바로', '바로', '대답하는', '것도'], tags=['d32']),\n",
       " TaggedDocument(words=['매력', '없어'], tags=['d33']),\n",
       " TaggedDocument(words=['메시지만', '읽고'], tags=['d34']),\n",
       " TaggedDocument(words=['확인', '안', '하는', '건', '기본'], tags=['d35']),\n",
       " TaggedDocument(words=['어어어', '너무', '심했나', 'boy'], tags=['d36']),\n",
       " TaggedDocument(words=['이러다가', '지칠까', '봐'], tags=['d37']),\n",
       " TaggedDocument(words=['걱정되긴', '하고'], tags=['d38']),\n",
       " TaggedDocument(words=['어어어', '안', '그러면', '내가', '더'], tags=['d39']),\n",
       " TaggedDocument(words=['빠질', '것만', '같어', '빠질', '것만', '같어'], tags=['d40']),\n",
       " TaggedDocument(words=['아', '답장을', '못해줘서', '미안해'], tags=['d41']),\n",
       " TaggedDocument(words=['친구를', '만나느라', 'shy', 'shy', 'shy'], tags=['d42']),\n",
       " TaggedDocument(words=['만나긴', '좀', '그렇구', '미안해'], tags=['d43']),\n",
       " TaggedDocument(words=['좀', '있다', '연락할게', 'later'], tags=['d44']),\n",
       " TaggedDocument(words=['조르지마', '어디', '가지', '않아'], tags=['d45']),\n",
       " TaggedDocument(words=['되어줄게', '너의', 'Baby'], tags=['d46']),\n",
       " TaggedDocument(words=['너무', '빨린', '싫어', '성의를', '더', '보여'], tags=['d47']),\n",
       " TaggedDocument(words=['내가', '널', '기다려줄게'], tags=['d48']),\n",
       " TaggedDocument(words=['CHEER', 'UP', 'BABY', 'CHEER', 'UP', 'BABY'], tags=['d49']),\n",
       " TaggedDocument(words=['좀', '더', '힘을', '내'], tags=['d50']),\n",
       " TaggedDocument(words=['여자', '가', '쉽게', '맘을', '주면', '안돼'], tags=['d51']),\n",
       " TaggedDocument(words=['그래야', '니가', '날', '더', '좋아', '하게', '될걸'], tags=['d52']),\n",
       " TaggedDocument(words=['태연하게', '연기할래', '아무렇지', '않게'], tags=['d53']),\n",
       " TaggedDocument(words=['내가', '널', '좋아', '하는', '맘', '모르게'], tags=['d54']),\n",
       " TaggedDocument(words=['just', 'get', 'it', 'together'], tags=['d55']),\n",
       " TaggedDocument(words=['and', 'then', 'baby', 'CHEER', 'UP'], tags=['d56']),\n",
       " TaggedDocument(words=['나도', '니가', '좋아', '상처', '입을까', '봐'], tags=['d57']),\n",
       " TaggedDocument(words=['걱정되지만', '여자', '니까', '이해해주길'], tags=['d58']),\n",
       " TaggedDocument(words=['속', '마음', '들킬', '까봐', '겁이나'], tags=['d59']),\n",
       " TaggedDocument(words=['지금처럼', '조금만', '더', '다가와'], tags=['d60']),\n",
       " TaggedDocument(words=['그리', '오래', '걸리진', '않아'], tags=['d61']),\n",
       " TaggedDocument(words=['just', 'get', 'it', 'together'], tags=['d62']),\n",
       " TaggedDocument(words=['and', 'then', 'baby', 'CHEER', 'UP'], tags=['d63']),\n",
       " TaggedDocument(words=['Be', 'a', 'man', 'a', 'real', 'man'], tags=['d64']),\n",
       " TaggedDocument(words=['gotta', 'see', 'u', 'love', 'me', 'like', 'a', 'real', 'man'], tags=['d65']),\n",
       " TaggedDocument(words=['Be', 'a', 'man', 'a', 'real', 'man'], tags=['d66']),\n",
       " TaggedDocument(words=['gotta', 'see', 'u', 'love', 'me', 'like', 'a', 'real', 'man'], tags=['d67']),\n",
       " TaggedDocument(words=['CHEER', 'UP', 'BABY', 'CHEER', 'UP', 'BABY'], tags=['d68']),\n",
       " TaggedDocument(words=['좀', '더', '힘을', '내'], tags=['d69']),\n",
       " TaggedDocument(words=['여자', '가', '쉽게', '맘을', '주면', '안돼'], tags=['d70']),\n",
       " TaggedDocument(words=['그래야', '니가', '날', '더', '좋아', '하게', '될걸'], tags=['d71']),\n",
       " TaggedDocument(words=['태연하게', '연기할래', '아무렇지', '않게'], tags=['d72']),\n",
       " TaggedDocument(words=['내가', '널', '좋아', '하는', '맘', '모르게'], tags=['d73']),\n",
       " TaggedDocument(words=['just', 'get', 'it', 'together'], tags=['d74']),\n",
       " TaggedDocument(words=['and', 'then', 'baby', 'CHEER', 'UP'], tags=['d75']),\n",
       " TaggedDocument(words=[], tags=['d76']),\n",
       " TaggedDocument(words=['HTTP://K2N', 'BLOG.COM'], tags=['d77']),\n",
       " TaggedDocument(words=[], tags=['d78'])]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(docs, min_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = model.docvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3605299e-03 -4.9551218e-03  6.4320973e-04 -3.1982341e-03\n",
      "  4.4268142e-03  3.4082234e-03 -5.5610308e-05 -3.3584442e-03\n",
      " -3.4386558e-03  3.9370586e-03 -3.2208264e-03 -2.0945859e-03\n",
      " -5.5775727e-04  4.6909028e-03 -8.3822437e-04 -2.6412073e-03\n",
      " -4.9597463e-03  3.0055246e-03  4.8844487e-04 -9.9924020e-04\n",
      " -4.4104201e-03  4.5410311e-03 -1.4134985e-05  2.0951689e-03\n",
      "  1.6765220e-03 -2.1535123e-03 -4.9690870e-03 -2.7008341e-03\n",
      " -4.3723034e-03 -2.1838325e-03 -4.7371862e-03  2.5483817e-03\n",
      " -4.9351221e-03 -1.3243871e-04 -7.3936710e-04 -1.4161090e-04\n",
      " -4.9034525e-03 -2.5488301e-03  4.6267419e-04  4.4306791e-03\n",
      "  1.7403271e-03  4.8091557e-04  4.6775737e-03  2.4558259e-03\n",
      " -6.6190143e-04  3.7965947e-03  1.4651486e-03 -2.3283160e-03\n",
      "  4.6461667e-03 -2.4500517e-03  3.2302451e-03  2.2956124e-03\n",
      " -3.2030870e-03 -1.7275230e-03 -3.1310250e-03 -3.4666355e-03\n",
      " -2.8409101e-03 -3.6558085e-03 -7.7481044e-04 -9.1449899e-04\n",
      " -7.2874362e-04 -4.0982035e-03  9.3519141e-04  4.9596098e-03\n",
      " -4.0754857e-03 -2.0528405e-03  1.1790267e-04 -3.2628360e-03\n",
      " -2.9778373e-03 -2.2291397e-03  8.7689381e-04  2.6052811e-03\n",
      " -3.7310387e-03 -4.0780357e-03  1.5236594e-03  4.6550183e-04\n",
      "  4.7078086e-03  1.5506744e-03 -5.3285813e-04  2.3079512e-03\n",
      "  3.2578674e-03 -1.1933394e-03  2.2429375e-03  7.8127638e-04\n",
      " -1.4486389e-04  5.5514893e-04 -1.4623435e-03  2.7832177e-03\n",
      " -2.8956998e-03  1.0872590e-03  4.8952023e-03 -3.7420860e-03\n",
      " -5.3199474e-04 -4.6247998e-03  3.8322336e-03 -2.2528253e-03\n",
      " -3.8023230e-03 -3.7310157e-05  2.1545717e-03  2.4610604e-03]\n",
      "[ 4.3877659e-04  2.2434726e-04  1.8318101e-03  1.1635442e-03\n",
      " -3.8142391e-03  4.1426723e-03 -6.3633523e-04 -4.2656943e-04\n",
      " -2.5124270e-03 -4.3944805e-03 -7.0610477e-05 -1.4170422e-03\n",
      "  3.6115843e-04  8.4045815e-04  2.4917015e-04 -4.3279575e-03\n",
      " -2.4216459e-03  8.8565372e-04  3.4303847e-03  2.4848762e-03\n",
      "  4.4665262e-03 -3.7070275e-03  1.6362238e-03  4.8960927e-03\n",
      " -8.0789835e-04  4.4942899e-03 -3.1790230e-03  3.5520142e-03\n",
      " -3.3282820e-05 -2.1119595e-03  4.7265068e-03 -4.3329646e-04\n",
      "  1.3527478e-03  3.0235511e-03  4.5507271e-03 -1.2406637e-03\n",
      " -3.7115340e-03  9.2069851e-04  1.7562759e-03  2.6826095e-04\n",
      "  3.5047594e-03  1.4773633e-04 -4.7547496e-03  1.1664794e-03\n",
      "  6.3833006e-04 -2.5481877e-03  4.8944587e-03  2.0382919e-03\n",
      "  4.1182786e-03  8.1440236e-04  3.9222250e-03 -4.6251556e-03\n",
      " -3.6497251e-04 -4.3635294e-03 -3.8218186e-03 -1.8686295e-04\n",
      "  4.7571580e-03 -1.4950230e-03  2.5989236e-03  2.3704660e-03\n",
      " -4.6750600e-03 -3.1009398e-03  4.5732493e-03  2.8061536e-03\n",
      " -4.6828948e-03  4.8648641e-03 -1.2772504e-03  4.5277672e-03\n",
      "  5.8709062e-04  1.5439840e-03  3.1371573e-03  6.9093943e-04\n",
      " -1.6194340e-03  2.6663176e-03 -7.3305162e-04  5.9363578e-04\n",
      " -4.7118706e-03  4.4740150e-03  4.0309588e-04 -4.8127971e-04\n",
      " -4.5794379e-03 -3.2799473e-04  4.3702321e-03  2.8618774e-03\n",
      "  3.6772431e-03  2.2036480e-03  6.5030338e-04 -1.9429082e-03\n",
      "  3.0371326e-04 -1.1285762e-03  1.4761145e-03 -3.7316005e-03\n",
      " -4.9971044e-03 -1.6033005e-03 -1.4952428e-03  4.6091806e-03\n",
      " -4.7763609e-03 -4.8478926e-03  2.1085297e-03  7.9439086e-04]\n",
      "[-4.4267508e-03 -6.9564738e-04  1.3977387e-03 -7.3172734e-05\n",
      " -3.5013712e-03 -1.4942893e-03  4.0464657e-03  4.1466397e-03\n",
      " -2.7281588e-03 -4.8400438e-03  3.8409389e-03  3.0961893e-03\n",
      " -3.6802986e-03  1.1074705e-03 -2.8006564e-04 -6.5136014e-04\n",
      " -3.0760516e-03  3.7149659e-03 -2.5661807e-03  4.1266342e-04\n",
      "  4.8793866e-03 -3.3090930e-03 -3.2879962e-03 -2.1558048e-03\n",
      "  2.2086456e-04  3.5792028e-03 -1.4716929e-03 -4.5359409e-03\n",
      " -2.6291545e-04  1.7471371e-03 -2.8366991e-03 -4.7031674e-03\n",
      "  3.7887900e-03 -5.6350435e-04 -1.7096962e-04 -1.8327346e-03\n",
      "  7.0895324e-04 -9.2313450e-04  2.3965823e-04  1.3779075e-03\n",
      " -1.0330408e-03 -2.4995832e-03 -2.3568889e-04 -3.7346650e-03\n",
      "  2.7256147e-03  3.9491761e-03  4.0911976e-04  1.5084666e-03\n",
      " -3.1744151e-03 -4.9886107e-03 -2.4484682e-03 -8.5446774e-04\n",
      "  3.0064408e-04 -4.4615916e-04  1.2655606e-03 -4.3595419e-03\n",
      " -2.9056293e-03 -3.5982544e-03 -4.7781793e-03  4.2627957e-03\n",
      " -3.8938159e-03 -3.9024409e-03 -4.9923044e-03 -2.5594370e-03\n",
      "  1.5780891e-03  1.8721392e-03  2.0626148e-04  2.6306345e-03\n",
      " -6.7975739e-04  2.9237454e-03  3.3557783e-03  2.4787325e-04\n",
      " -9.8102703e-04  3.4632457e-03  4.3551777e-03  1.4553898e-03\n",
      " -3.4767312e-03  4.8734524e-04  8.3529571e-04  4.7906949e-03\n",
      "  3.6098387e-03  1.3410634e-03 -1.3259883e-03  4.8294887e-03\n",
      "  2.8450855e-03 -4.4484367e-03 -5.4895988e-04 -7.2956900e-04\n",
      " -4.7514844e-03  1.6936838e-03  4.7969418e-03 -3.9768671e-03\n",
      "  2.3522689e-03  4.0512551e-03 -9.4813702e-04 -1.9638084e-03\n",
      " -2.3842691e-05 -4.3719686e-03 -6.8899797e-04  3.5653380e-03]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3) :\n",
    "    print(vectors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc2vec기반 벡터 유사도 \n",
    "def distance(a_doctag, b_doctag, vectors) :\n",
    "    sim = vectors.similarity(a_doctag, b_doctag)\n",
    "    return sim*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  ['CHEER', 'UP'] d0\n",
      "[-1.3605299e-03 -4.9551218e-03  6.4320973e-04 -3.1982341e-03\n",
      "  4.4268142e-03  3.4082234e-03 -5.5610308e-05 -3.3584442e-03\n",
      " -3.4386558e-03  3.9370586e-03 -3.2208264e-03 -2.0945859e-03\n",
      " -5.5775727e-04  4.6909028e-03 -8.3822437e-04 -2.6412073e-03\n",
      " -4.9597463e-03  3.0055246e-03  4.8844487e-04 -9.9924020e-04\n",
      " -4.4104201e-03  4.5410311e-03 -1.4134985e-05  2.0951689e-03\n",
      "  1.6765220e-03 -2.1535123e-03 -4.9690870e-03 -2.7008341e-03\n",
      " -4.3723034e-03 -2.1838325e-03 -4.7371862e-03  2.5483817e-03\n",
      " -4.9351221e-03 -1.3243871e-04 -7.3936710e-04 -1.4161090e-04\n",
      " -4.9034525e-03 -2.5488301e-03  4.6267419e-04  4.4306791e-03\n",
      "  1.7403271e-03  4.8091557e-04  4.6775737e-03  2.4558259e-03\n",
      " -6.6190143e-04  3.7965947e-03  1.4651486e-03 -2.3283160e-03\n",
      "  4.6461667e-03 -2.4500517e-03  3.2302451e-03  2.2956124e-03\n",
      " -3.2030870e-03 -1.7275230e-03 -3.1310250e-03 -3.4666355e-03\n",
      " -2.8409101e-03 -3.6558085e-03 -7.7481044e-04 -9.1449899e-04\n",
      " -7.2874362e-04 -4.0982035e-03  9.3519141e-04  4.9596098e-03\n",
      " -4.0754857e-03 -2.0528405e-03  1.1790267e-04 -3.2628360e-03\n",
      " -2.9778373e-03 -2.2291397e-03  8.7689381e-04  2.6052811e-03\n",
      " -3.7310387e-03 -4.0780357e-03  1.5236594e-03  4.6550183e-04\n",
      "  4.7078086e-03  1.5506744e-03 -5.3285813e-04  2.3079512e-03\n",
      "  3.2578674e-03 -1.1933394e-03  2.2429375e-03  7.8127638e-04\n",
      " -1.4486389e-04  5.5514893e-04 -1.4623435e-03  2.7832177e-03\n",
      " -2.8956998e-03  1.0872590e-03  4.8952023e-03 -3.7420860e-03\n",
      " -5.3199474e-04 -4.6247998e-03  3.8322336e-03 -2.2528253e-03\n",
      " -3.8023230e-03 -3.7310157e-05  2.1545717e-03  2.4610604e-03]\n",
      "B:  ['이젠', '나를', '배려', '해줘'] d3\n",
      "[ 3.2491328e-03  7.1090215e-04 -2.7161281e-05 -2.3146234e-03\n",
      " -1.4069683e-03 -4.8270924e-03 -1.9606224e-03  3.9852923e-03\n",
      " -1.4496733e-03  8.5326307e-04  1.2165764e-03 -3.3238190e-03\n",
      "  3.1587514e-03  9.1244234e-04 -2.4789849e-03  4.5363382e-03\n",
      "  4.2812927e-03  3.3755128e-03 -4.9798000e-03 -7.8511442e-04\n",
      "  2.3399035e-03 -2.9274377e-03  1.4618956e-03  2.4535176e-03\n",
      "  1.6874820e-03 -8.7828335e-04 -7.6996192e-04 -4.6177073e-03\n",
      "  3.4920970e-04  1.3129411e-03 -5.1112944e-04 -2.3980963e-03\n",
      " -8.1497239e-04 -1.0307080e-03 -2.1936453e-03  6.8878224e-05\n",
      "  1.8026853e-03 -4.6162084e-03 -3.5915363e-03 -2.7602266e-03\n",
      " -3.1288078e-03  1.2767917e-03 -4.0043755e-03 -2.1624153e-03\n",
      "  6.8267173e-04 -1.6978015e-03 -2.1708200e-03  3.9177979e-04\n",
      "  3.6089690e-03  1.3884509e-03  1.9688446e-03  4.3411446e-03\n",
      " -3.3373185e-03  2.3367659e-03 -3.7528847e-03 -3.3241382e-03\n",
      "  4.0214657e-04  4.1026366e-03 -4.2420798e-03 -3.1949137e-03\n",
      "  3.7420453e-03  3.9839162e-03  6.6488312e-04 -1.0751961e-03\n",
      "  4.3399329e-03  3.8036858e-03 -3.1679838e-03  3.9312760e-03\n",
      " -1.2043623e-03  1.9862419e-03 -1.4850860e-03  4.9240873e-03\n",
      "  1.6440463e-04 -2.4989045e-03 -3.4592052e-03  1.3259346e-04\n",
      " -3.2531079e-03  1.5997759e-03 -2.2379509e-03  1.0864483e-03\n",
      " -3.6664123e-03 -4.8631858e-03 -3.5826212e-03  4.8091006e-03\n",
      " -3.3159496e-03  2.7046972e-03 -2.0528198e-03 -1.7323112e-03\n",
      " -4.9511679e-03 -4.3681026e-03  1.6189188e-03 -3.0160074e-03\n",
      " -7.5759034e-04  3.1471250e-03 -6.7626312e-04 -1.6636135e-03\n",
      " -3.0457233e-03  4.8595583e-03 -2.4064393e-03 -4.5008061e-04]\n",
      "-11.08 % similar\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "a_doctag = vectors.index2entity[a]\n",
    "print(\"A: \", corpus[a], a_doctag)\n",
    "print(vectors[a])\n",
    "\n",
    "b = 3\n",
    "b_doctag = vectors.index2entity[b]\n",
    "print(\"B: \", corpus[b], b_doctag)\n",
    "print(vectors[b])\n",
    "\n",
    "sim = distance(a_doctag, b_doctag, vectors)\n",
    "\n",
    "print(round(sim,2),'% similar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  ['이젠', '나를', '배려', '해줘'] d3\n",
      "[ 3.2491328e-03  7.1090215e-04 -2.7161281e-05 -2.3146234e-03\n",
      " -1.4069683e-03 -4.8270924e-03 -1.9606224e-03  3.9852923e-03\n",
      " -1.4496733e-03  8.5326307e-04  1.2165764e-03 -3.3238190e-03\n",
      "  3.1587514e-03  9.1244234e-04 -2.4789849e-03  4.5363382e-03\n",
      "  4.2812927e-03  3.3755128e-03 -4.9798000e-03 -7.8511442e-04\n",
      "  2.3399035e-03 -2.9274377e-03  1.4618956e-03  2.4535176e-03\n",
      "  1.6874820e-03 -8.7828335e-04 -7.6996192e-04 -4.6177073e-03\n",
      "  3.4920970e-04  1.3129411e-03 -5.1112944e-04 -2.3980963e-03\n",
      " -8.1497239e-04 -1.0307080e-03 -2.1936453e-03  6.8878224e-05\n",
      "  1.8026853e-03 -4.6162084e-03 -3.5915363e-03 -2.7602266e-03\n",
      " -3.1288078e-03  1.2767917e-03 -4.0043755e-03 -2.1624153e-03\n",
      "  6.8267173e-04 -1.6978015e-03 -2.1708200e-03  3.9177979e-04\n",
      "  3.6089690e-03  1.3884509e-03  1.9688446e-03  4.3411446e-03\n",
      " -3.3373185e-03  2.3367659e-03 -3.7528847e-03 -3.3241382e-03\n",
      "  4.0214657e-04  4.1026366e-03 -4.2420798e-03 -3.1949137e-03\n",
      "  3.7420453e-03  3.9839162e-03  6.6488312e-04 -1.0751961e-03\n",
      "  4.3399329e-03  3.8036858e-03 -3.1679838e-03  3.9312760e-03\n",
      " -1.2043623e-03  1.9862419e-03 -1.4850860e-03  4.9240873e-03\n",
      "  1.6440463e-04 -2.4989045e-03 -3.4592052e-03  1.3259346e-04\n",
      " -3.2531079e-03  1.5997759e-03 -2.2379509e-03  1.0864483e-03\n",
      " -3.6664123e-03 -4.8631858e-03 -3.5826212e-03  4.8091006e-03\n",
      " -3.3159496e-03  2.7046972e-03 -2.0528198e-03 -1.7323112e-03\n",
      " -4.9511679e-03 -4.3681026e-03  1.6189188e-03 -3.0160074e-03\n",
      " -7.5759034e-04  3.1471250e-03 -6.7626312e-04 -1.6636135e-03\n",
      " -3.0457233e-03  4.8595583e-03 -2.4064393e-03 -4.5008061e-04]\n",
      "B:  ['이젠', '나를', '배려', '해줘'] d3\n",
      "[ 3.2491328e-03  7.1090215e-04 -2.7161281e-05 -2.3146234e-03\n",
      " -1.4069683e-03 -4.8270924e-03 -1.9606224e-03  3.9852923e-03\n",
      " -1.4496733e-03  8.5326307e-04  1.2165764e-03 -3.3238190e-03\n",
      "  3.1587514e-03  9.1244234e-04 -2.4789849e-03  4.5363382e-03\n",
      "  4.2812927e-03  3.3755128e-03 -4.9798000e-03 -7.8511442e-04\n",
      "  2.3399035e-03 -2.9274377e-03  1.4618956e-03  2.4535176e-03\n",
      "  1.6874820e-03 -8.7828335e-04 -7.6996192e-04 -4.6177073e-03\n",
      "  3.4920970e-04  1.3129411e-03 -5.1112944e-04 -2.3980963e-03\n",
      " -8.1497239e-04 -1.0307080e-03 -2.1936453e-03  6.8878224e-05\n",
      "  1.8026853e-03 -4.6162084e-03 -3.5915363e-03 -2.7602266e-03\n",
      " -3.1288078e-03  1.2767917e-03 -4.0043755e-03 -2.1624153e-03\n",
      "  6.8267173e-04 -1.6978015e-03 -2.1708200e-03  3.9177979e-04\n",
      "  3.6089690e-03  1.3884509e-03  1.9688446e-03  4.3411446e-03\n",
      " -3.3373185e-03  2.3367659e-03 -3.7528847e-03 -3.3241382e-03\n",
      "  4.0214657e-04  4.1026366e-03 -4.2420798e-03 -3.1949137e-03\n",
      "  3.7420453e-03  3.9839162e-03  6.6488312e-04 -1.0751961e-03\n",
      "  4.3399329e-03  3.8036858e-03 -3.1679838e-03  3.9312760e-03\n",
      " -1.2043623e-03  1.9862419e-03 -1.4850860e-03  4.9240873e-03\n",
      "  1.6440463e-04 -2.4989045e-03 -3.4592052e-03  1.3259346e-04\n",
      " -3.2531079e-03  1.5997759e-03 -2.2379509e-03  1.0864483e-03\n",
      " -3.6664123e-03 -4.8631858e-03 -3.5826212e-03  4.8091006e-03\n",
      " -3.3159496e-03  2.7046972e-03 -2.0528198e-03 -1.7323112e-03\n",
      " -4.9511679e-03 -4.3681026e-03  1.6189188e-03 -3.0160074e-03\n",
      " -7.5759034e-04  3.1471250e-03 -6.7626312e-04 -1.6636135e-03\n",
      " -3.0457233e-03  4.8595583e-03 -2.4064393e-03 -4.5008061e-04]\n",
      "100.0 % similar\n"
     ]
    }
   ],
   "source": [
    "a = 3\n",
    "a_doctag = vectors.index2entity[a]\n",
    "print(\"A: \", corpus[a], a_doctag)\n",
    "print(vectors[a])\n",
    "\n",
    "b = 3\n",
    "b_doctag = vectors.index2entity[b]\n",
    "print(\"B: \", corpus[b], b_doctag)\n",
    "print(vectors[b])\n",
    "\n",
    "sim = distance(a_doctag, b_doctag, vectors)\n",
    "\n",
    "print(round(sim,2),'% similar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  ['자꾸', '만', '봐', '자꾸', '자꾸', '만', '와'] d5\n",
      "[ 4.9744649e-03  1.3063629e-03  4.3983497e-03 -2.6128520e-03\n",
      " -2.6264319e-03  1.5924338e-03  5.0056553e-03  1.8458734e-03\n",
      "  9.0326869e-04 -1.6680191e-04  1.7456752e-03  4.1497886e-04\n",
      "  4.5265998e-03  1.2190437e-03 -3.0204274e-03 -1.6526962e-03\n",
      " -2.2982252e-03 -2.5420394e-03  2.0805870e-03  3.3668738e-03\n",
      "  3.3744788e-03  5.7537219e-04  6.5630517e-04  1.4987971e-03\n",
      " -4.4436618e-03 -2.1766955e-03 -3.1012702e-03 -2.8978421e-03\n",
      "  6.7165575e-04  1.3199238e-03  1.8868636e-03  4.0666522e-03\n",
      "  9.1044401e-04 -2.4786401e-03 -2.9423998e-05 -1.5440270e-03\n",
      "  4.5353626e-03  4.4620582e-03 -9.8900324e-05  1.8128047e-03\n",
      "  2.9826069e-03 -4.6059079e-03 -4.2957631e-03 -4.3336581e-03\n",
      " -1.8758045e-03  2.9721744e-03 -1.9718010e-03 -4.8088743e-03\n",
      "  4.7251517e-03  1.4109866e-03 -2.3168100e-03  3.5558599e-03\n",
      "  1.0009286e-03  4.4028573e-03 -4.8340266e-03 -3.4305216e-03\n",
      " -1.5632069e-03  4.3344107e-03 -4.0552816e-03 -2.3120465e-03\n",
      " -3.0983952e-03  2.5032803e-03 -4.1890158e-03 -3.8405824e-03\n",
      " -2.2125097e-04  1.4612072e-03 -2.3915519e-03  4.8064921e-04\n",
      " -1.9843216e-04  4.9865909e-04  3.8292874e-03  2.7891446e-03\n",
      "  4.5701927e-03  3.0887285e-03  1.0975394e-03  2.8144233e-03\n",
      " -7.3127938e-04  4.3413690e-03  3.8510943e-03  3.4007987e-03\n",
      "  6.0061627e-04  2.5245687e-03 -1.2944342e-03 -2.4202697e-03\n",
      " -1.5485968e-03  2.3236035e-03  2.5459437e-03 -3.1785180e-03\n",
      " -8.4414362e-04  4.0048836e-03 -1.5268065e-03  3.8705419e-03\n",
      "  2.7771324e-03  4.7171582e-03 -2.0958055e-03 -3.3454257e-03\n",
      " -1.3702142e-03  3.7751888e-04 -3.3297623e-03 -2.1690594e-03]\n",
      "B:  ['내가', '널', '좋아', '하는', '맘', '모르게'] d25\n",
      "[-1.9671749e-03 -3.6263696e-03  2.8150105e-03  1.7452380e-03\n",
      " -4.7759977e-03  1.4190105e-03 -3.8031964e-03 -1.8643719e-03\n",
      "  2.8324155e-03  9.5055497e-04 -4.5066867e-03  1.3949458e-03\n",
      " -2.5886032e-03  1.6615659e-03  1.2403869e-03 -2.4598066e-04\n",
      " -4.5208600e-03  1.3028602e-03 -1.3580762e-03 -1.5616248e-03\n",
      " -1.5487642e-03 -2.6751875e-03  2.4127362e-04  5.5375026e-04\n",
      " -4.0621459e-03 -1.9088933e-03 -1.8183889e-03  4.0620491e-03\n",
      " -4.1089556e-03  3.9858269e-03 -2.1682433e-03  1.4083639e-03\n",
      " -3.8022622e-03 -4.4688191e-03 -3.7986579e-04  1.8105282e-03\n",
      "  4.6564825e-04  9.0088334e-04 -4.5595448e-03 -4.7507328e-05\n",
      "  1.9958143e-03  4.1977656e-03  1.8552445e-03 -1.4596371e-03\n",
      "  4.3792902e-03 -1.3245869e-03  2.8748482e-03  3.7934373e-03\n",
      " -8.5537729e-04 -3.3844435e-03  2.9084495e-06  2.5622856e-03\n",
      " -4.1198744e-03 -7.0809957e-04  4.5801564e-03  4.6245498e-03\n",
      " -2.1811179e-03  3.0075437e-03 -3.5263349e-03  1.4220913e-03\n",
      "  1.0287084e-03 -2.7191336e-03  2.9214814e-03  3.6758617e-03\n",
      " -3.1771418e-03  4.7775921e-03 -1.3764118e-03  3.2862457e-03\n",
      " -3.2673453e-03 -1.0658979e-03  3.0194526e-03 -3.0569332e-03\n",
      "  3.3074261e-03  3.1492445e-03  2.3500039e-03 -6.0515304e-05\n",
      " -4.0024864e-03 -4.4568893e-03  1.9784733e-03 -1.1565787e-03\n",
      " -1.4628081e-04  1.5406435e-03 -1.9110559e-03 -1.3120053e-03\n",
      " -2.4772021e-03  3.4607826e-03 -4.8828584e-05 -4.8473435e-03\n",
      " -6.3538202e-04  4.8851566e-03  1.5120581e-03  3.7410583e-03\n",
      "  1.8544405e-04 -3.8021095e-03 -3.9583072e-03  1.5991740e-03\n",
      "  2.2674196e-03  4.8764772e-03 -3.6269224e-03  1.2660150e-03]\n",
      "-2.41 % similar\n"
     ]
    }
   ],
   "source": [
    "a = 5\n",
    "a_doctag = vectors.index2entity[a]\n",
    "print(\"A: \", corpus[a], a_doctag)\n",
    "print(vectors[a])\n",
    "\n",
    "b = 25\n",
    "b_doctag = vectors.index2entity[b]\n",
    "print(\"B: \", corpus[b], b_doctag)\n",
    "print(vectors[b])\n",
    "\n",
    "sim = distance(a_doctag, b_doctag, vectors)\n",
    "\n",
    "print(round(sim,2),'% similar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "* Word2Vec\n",
    "* Glove\n",
    "* FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 출처 - models.word2vec – Deep learning with word2vec - https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 영어 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['my', 'name', 'is', 'jamie'], ['jamie', 'is', 'cute']]\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "documents_en = [[\"my\", \"name\", \"is\", \"jamie\"], [\"jamie\", \"is\", \"cute\"]]\n",
    "\n",
    "pprint(documents_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "w2v_en = gensim.models.Word2Vec(min_count=1) # 예) Word2Vec(sentences, size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 사전 만들기\n",
    "w2v_en.build_vocab(documents_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 70)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습\n",
    "w2v_en.train(documents_en, total_examples=len(documents_en), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 모델 저장 및 불러오기 - 이것은 나중에 이 모델을 다시 활용하려할 때 써보기. \n",
    "fname = 'model_w2v_en.wv'\n",
    "w2v_en.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_w2v_en.wv\r\n"
     ]
    }
   ],
   "source": [
    "%ls model_w2v_en.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_w2v_en = gensim.models.Word2Vec.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어의 벡터값 얻기\n",
    "vectors_en = my_w2v_en.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8463916e-03, -2.4474319e-03, -1.3874241e-03,  4.8990846e-03,\n",
       "        2.7666870e-03, -2.5682717e-03, -1.0529022e-03,  1.5984683e-03,\n",
       "        3.5162780e-03, -4.3272837e-03, -7.5240212e-04,  3.5976199e-03,\n",
       "        4.1191247e-03, -4.1965623e-03, -4.7344430e-03,  3.0092369e-03,\n",
       "        4.6412502e-03,  4.8348550e-03, -1.1275733e-03,  8.3893735e-04,\n",
       "        2.7623824e-03,  3.0995489e-03,  4.0115002e-03, -2.3493078e-03,\n",
       "       -2.7641570e-03, -3.0821294e-03,  2.0122917e-03,  4.8594424e-03,\n",
       "        1.1204177e-03,  1.1255337e-03, -1.6868635e-03,  1.0017377e-03,\n",
       "       -5.1385420e-04, -1.0345953e-03,  8.1620106e-05, -3.5002567e-03,\n",
       "       -2.5435812e-03,  2.7102412e-04,  2.2499840e-04,  4.0757204e-03,\n",
       "        1.3699288e-03, -3.1554259e-03,  4.6244864e-03, -2.2115754e-03,\n",
       "        3.0307646e-03,  4.8729051e-03,  2.5988133e-03,  4.5161145e-03,\n",
       "        4.4576917e-03, -9.9189021e-04, -3.4095140e-03, -1.6049502e-03,\n",
       "        7.8812923e-04, -1.2764394e-03,  9.1111817e-04,  1.2262160e-03,\n",
       "       -3.5376532e-03, -3.2359785e-03,  3.8771390e-03,  4.5660012e-03,\n",
       "       -3.2382126e-03,  8.7891975e-05,  3.1498622e-04,  6.1035727e-04,\n",
       "        2.0707710e-04, -2.5505391e-03, -3.9337124e-03,  3.8460772e-03,\n",
       "       -3.0739716e-04,  4.5979586e-03,  3.5736756e-03,  3.1070798e-03,\n",
       "        3.5833020e-03, -4.6356870e-03,  3.4887125e-03, -1.8172831e-03,\n",
       "       -3.2833003e-04,  4.6549728e-03,  4.9287518e-03, -1.7185952e-03,\n",
       "        4.4387798e-03, -1.8240118e-03,  1.6595197e-03, -1.7176967e-03,\n",
       "       -4.8352624e-03, -7.1062637e-04,  1.4587811e-03,  2.0944010e-03,\n",
       "       -4.8194095e-04,  5.5192888e-04, -4.8357956e-03, -4.5038569e-03,\n",
       "        3.2388808e-03, -4.0468723e-03, -1.1803379e-03, -4.6479222e-03,\n",
       "       -3.3784809e-03,  4.8204944e-03,  3.6008381e-03, -3.6163430e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_en['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 한국어 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['CHEER', 'UP'],\n",
      " [],\n",
      " ['매일', '울리는', '벨벨벨'],\n",
      " ['이젠', '나를', '배려', '해줘'],\n",
      " ['배터리', '낭비하긴', '싫어'],\n",
      " ['자꾸', '만', '봐', '자꾸', '자꾸', '만', '와'],\n",
      " ['전화가', '펑', '터질', '것만', '같아'],\n",
      " ['몰라', '몰라', '숨도', '못', '쉰대'],\n",
      " ['나', '때문에', '힘들어'],\n",
      " ['쿵', '심장이', '떨어진대', '왜'],\n",
      " ['걔', '말은', '나', '너무', '예쁘대'],\n",
      " ['자랑', '하는건', '아니구'],\n",
      " ['아', '아까는', '못', '받아서', '미안해'],\n",
      " ['친구를', '만나느라', 'shy', 'shy', 'shy'],\n",
      " ['만나긴', '좀', '그렇구', '미안해'],\n",
      " ['좀', '있다', '연락할게', 'later'],\n",
      " ['조르지마', '얼마', '가지', '않아'],\n",
      " ['부르게', '해줄게', 'Baby'],\n",
      " ['아직은', '좀', '일러', '내', '맘', '같긴', '일러'],\n",
      " ['하지만', '더', '보여줄래'],\n",
      " ['CHEER', 'UP', 'BABY', 'CHEER', 'UP', 'BABY'],\n",
      " ['좀', '더', '힘을', '내'],\n",
      " ['여자', '가', '쉽게', '맘을', '주면', '안돼'],\n",
      " ['그래야', '니가', '날', '더', '좋아', '하게', '될걸'],\n",
      " ['태연하게', '연기할래', '아무렇지', '않게'],\n",
      " ['내가', '널', '좋아', '하는', '맘', '모르게'],\n",
      " ['just', 'get', 'it', 'together'],\n",
      " ['and', 'then', 'baby', 'CHEER', 'UP'],\n",
      " ['안절부절', '목소리가'],\n",
      " ['여기', '까지', '들려'],\n",
      " ['땀에', '젖은', '전화기가'],\n",
      " ['여기', '서도', '보여'],\n",
      " ['바로', '바로', '대답하는', '것도'],\n",
      " ['매력', '없어'],\n",
      " ['메시지만', '읽고'],\n",
      " ['확인', '안', '하는', '건', '기본'],\n",
      " ['어어어', '너무', '심했나', 'boy'],\n",
      " ['이러다가', '지칠까', '봐'],\n",
      " ['걱정되긴', '하고'],\n",
      " ['어어어', '안', '그러면', '내가', '더'],\n",
      " ['빠질', '것만', '같어', '빠질', '것만', '같어'],\n",
      " ['아', '답장을', '못해줘서', '미안해'],\n",
      " ['친구를', '만나느라', 'shy', 'shy', 'shy'],\n",
      " ['만나긴', '좀', '그렇구', '미안해'],\n",
      " ['좀', '있다', '연락할게', 'later'],\n",
      " ['조르지마', '어디', '가지', '않아'],\n",
      " ['되어줄게', '너의', 'Baby'],\n",
      " ['너무', '빨린', '싫어', '성의를', '더', '보여'],\n",
      " ['내가', '널', '기다려줄게'],\n",
      " ['CHEER', 'UP', 'BABY', 'CHEER', 'UP', 'BABY'],\n",
      " ['좀', '더', '힘을', '내'],\n",
      " ['여자', '가', '쉽게', '맘을', '주면', '안돼'],\n",
      " ['그래야', '니가', '날', '더', '좋아', '하게', '될걸'],\n",
      " ['태연하게', '연기할래', '아무렇지', '않게'],\n",
      " ['내가', '널', '좋아', '하는', '맘', '모르게'],\n",
      " ['just', 'get', 'it', 'together'],\n",
      " ['and', 'then', 'baby', 'CHEER', 'UP'],\n",
      " ['나도', '니가', '좋아', '상처', '입을까', '봐'],\n",
      " ['걱정되지만', '여자', '니까', '이해해주길'],\n",
      " ['속', '마음', '들킬', '까봐', '겁이나'],\n",
      " ['지금처럼', '조금만', '더', '다가와'],\n",
      " ['그리', '오래', '걸리진', '않아'],\n",
      " ['just', 'get', 'it', 'together'],\n",
      " ['and', 'then', 'baby', 'CHEER', 'UP'],\n",
      " ['Be', 'a', 'man', 'a', 'real', 'man'],\n",
      " ['gotta', 'see', 'u', 'love', 'me', 'like', 'a', 'real', 'man'],\n",
      " ['Be', 'a', 'man', 'a', 'real', 'man'],\n",
      " ['gotta', 'see', 'u', 'love', 'me', 'like', 'a', 'real', 'man'],\n",
      " ['CHEER', 'UP', 'BABY', 'CHEER', 'UP', 'BABY'],\n",
      " ['좀', '더', '힘을', '내'],\n",
      " ['여자', '가', '쉽게', '맘을', '주면', '안돼'],\n",
      " ['그래야', '니가', '날', '더', '좋아', '하게', '될걸'],\n",
      " ['태연하게', '연기할래', '아무렇지', '않게'],\n",
      " ['내가', '널', '좋아', '하는', '맘', '모르게'],\n",
      " ['just', 'get', 'it', 'together'],\n",
      " ['and', 'then', 'baby', 'CHEER', 'UP'],\n",
      " [],\n",
      " ['HTTP://K2N', 'BLOG.COM'],\n",
      " []]\n"
     ]
    }
   ],
   "source": [
    "documents_ko = [list(tokenize(sent, tokenizer)) for sent in lyrics]\n",
    "\n",
    "pprint(documents_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "w2v_ko = gensim.models.Word2Vec(min_count=1) # 예) Word2Vec(sentences, size=100, window=5, min_count=5, workers=4)\n",
    "# 모델 사전 만들기\n",
    "w2v_ko.build_vocab(documents_ko)\n",
    "# 학습\n",
    "w2v_ko.train(documents_ko, total_examples=len(documents_ko), epochs=10)\n",
    "# 모델 저장\n",
    "fname = 'model_w2v_ko.wv'\n",
    "w2v_ko.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어의 벡터값 얻기\n",
    "vectors_ko = w2v_ko.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00299507,  0.00389504, -0.00402283, -0.00496571, -0.00286623,\n",
       "        0.0009864 , -0.0042139 ,  0.00134176,  0.00015939, -0.00359018,\n",
       "        0.00363198,  0.00025816,  0.00398525,  0.00473751,  0.00380818,\n",
       "       -0.00395916, -0.00234931,  0.00471063, -0.00311525, -0.00092859,\n",
       "       -0.00479069,  0.00348141,  0.00422892,  0.00425649, -0.0029851 ,\n",
       "        0.00317291,  0.00463596,  0.00278836,  0.00231364,  0.00217661,\n",
       "       -0.00463204,  0.00366445,  0.00257002, -0.00154999, -0.00412736,\n",
       "        0.00445884,  0.00200433, -0.00264274, -0.00037009, -0.00267405,\n",
       "        0.00313294,  0.00278946, -0.00180913,  0.00306309,  0.00143279,\n",
       "        0.0030039 ,  0.0014327 , -0.00355948, -0.00220458, -0.0001424 ,\n",
       "       -0.00205512,  0.00276355,  0.00023416, -0.00326569, -0.00431944,\n",
       "       -0.00316572, -0.00451421, -0.00380698, -0.00302657, -0.00318542,\n",
       "       -0.00463803, -0.0014342 ,  0.00180713,  0.00289438,  0.00352388,\n",
       "        0.00198569,  0.00469513,  0.00028651,  0.00256516,  0.00113238,\n",
       "       -0.00106267, -0.00471953,  0.0032714 , -0.00318383,  0.00492207,\n",
       "       -0.00054508, -0.00372592,  0.00368847, -0.00144467,  0.00066165,\n",
       "       -0.00076777,  0.00235922,  0.00458736, -0.00179946, -0.00385671,\n",
       "       -0.00072966,  0.00350979,  0.00090593, -0.00068007,  0.00019768,\n",
       "       -0.0017692 , -0.00117294, -0.004067  ,  0.00178135, -0.00438745,\n",
       "       -0.00229752, -0.00337573,  0.0024562 ,  0.00489224, -0.00296155],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_ko['조르지마']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotly로 시각화 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def reduce_dimensions(model, plot_in_notebook = True):\n",
    "\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    vectors = []        # positions in vector space\n",
    "    labels = []         # keep track of words to label our data again later\n",
    "    for word in model.wv.vocab:\n",
    "        vectors.append(model[word])\n",
    "        labels.append(word)\n",
    "\n",
    "\n",
    "    # convert both lists into numpy vectors for reduction\n",
    "    vectors = np.asarray(vectors)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    # reduce using t-SNE\n",
    "    vectors = np.asarray(vectors)\n",
    "    logging.info('starting tSNE dimensionality reduction. This may take some time.')\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "        \n",
    "    # Create a trace\n",
    "    trace = go.Scatter(\n",
    "        x=x_vals,\n",
    "        y=y_vals,\n",
    "        mode='text',\n",
    "        text=labels\n",
    "        )\n",
    "    \n",
    "    data = [trace]\n",
    "    \n",
    "    logging.info('All done. Plotting.')\n",
    "    \n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moodern/anaconda3/envs/deepnlp/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "\n",
      "2019-04-23 08:09:58,422 : INFO : starting tSNE dimensionality reduction. This may take some time.\n",
      "2019-04-23 08:09:58,757 : INFO : All done. Plotting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "text",
         "text": [
          "my",
          "name",
          "is",
          "jamie",
          "cute"
         ],
         "type": "scatter",
         "uid": "89f571b2-87cc-433c-a639-e065e1d922e3",
         "x": [
          63.926395416259766,
          -79.67578125,
          -104.6999740600586,
          -200.45889282226562,
          34.45746612548828
         ],
         "y": [
          -2.4309916496276855,
          8.64052963256836,
          -183.96826171875,
          -69.81289672851562,
          -148.48712158203125
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"8414fcaf-f864-49c3-84f0-78d82f3585f6\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"8414fcaf-f864-49c3-84f0-78d82f3585f6\")) {\n",
       "    Plotly.newPlot(\"8414fcaf-f864-49c3-84f0-78d82f3585f6\", [{\"mode\": \"text\", \"text\": [\"my\", \"name\", \"is\", \"jamie\", \"cute\"], \"x\": [63.926395416259766, -79.67578125, -104.6999740600586, -200.45889282226562, 34.45746612548828], \"y\": [-2.4309916496276855, 8.64052963256836, -183.96826171875, -69.81289672851562, -148.48712158203125], \"type\": \"scatter\", \"uid\": \"1d8ebd44-914e-4a16-9236-aa5edd760db4\"}], {}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"8414fcaf-f864-49c3-84f0-78d82f3585f6\")) {window._Plotly.Plots.resize(document.getElementById(\"8414fcaf-f864-49c3-84f0-78d82f3585f6\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"8414fcaf-f864-49c3-84f0-78d82f3585f6\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"8414fcaf-f864-49c3-84f0-78d82f3585f6\")) {\n",
       "    Plotly.newPlot(\"8414fcaf-f864-49c3-84f0-78d82f3585f6\", [{\"mode\": \"text\", \"text\": [\"my\", \"name\", \"is\", \"jamie\", \"cute\"], \"x\": [63.926395416259766, -79.67578125, -104.6999740600586, -200.45889282226562, 34.45746612548828], \"y\": [-2.4309916496276855, 8.64052963256836, -183.96826171875, -69.81289672851562, -148.48712158203125], \"type\": \"scatter\", \"uid\": \"1d8ebd44-914e-4a16-9236-aa5edd760db4\"}], {}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"8414fcaf-f864-49c3-84f0-78d82f3585f6\")) {window._Plotly.Plots.resize(document.getElementById(\"8414fcaf-f864-49c3-84f0-78d82f3585f6\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 영어 예시\n",
    "reduce_dimensions(w2v_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moodern/anaconda3/envs/deepnlp/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "\n",
      "2019-04-23 08:10:58,746 : INFO : starting tSNE dimensionality reduction. This may take some time.\n",
      "2019-04-23 08:10:59,560 : INFO : All done. Plotting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "text",
         "text": [
          "CHEER",
          "UP",
          "매일",
          "울리는",
          "벨벨벨",
          "이젠",
          "나를",
          "배려",
          "해줘",
          "배터리",
          "낭비하긴",
          "싫어",
          "자꾸",
          "만",
          "봐",
          "와",
          "전화가",
          "펑",
          "터질",
          "것만",
          "같아",
          "몰라",
          "숨도",
          "못",
          "쉰대",
          "나",
          "때문에",
          "힘들어",
          "쿵",
          "심장이",
          "떨어진대",
          "왜",
          "걔",
          "말은",
          "너무",
          "예쁘대",
          "자랑",
          "하는건",
          "아니구",
          "아",
          "아까는",
          "받아서",
          "미안해",
          "친구를",
          "만나느라",
          "shy",
          "만나긴",
          "좀",
          "그렇구",
          "있다",
          "연락할게",
          "later",
          "조르지마",
          "얼마",
          "가지",
          "않아",
          "부르게",
          "해줄게",
          "Baby",
          "아직은",
          "일러",
          "내",
          "맘",
          "같긴",
          "하지만",
          "더",
          "보여줄래",
          "BABY",
          "힘을",
          "여자",
          "가",
          "쉽게",
          "맘을",
          "주면",
          "안돼",
          "그래야",
          "니가",
          "날",
          "좋아",
          "하게",
          "될걸",
          "태연하게",
          "연기할래",
          "아무렇지",
          "않게",
          "내가",
          "널",
          "하는",
          "모르게",
          "just",
          "get",
          "it",
          "together",
          "and",
          "then",
          "baby",
          "안절부절",
          "목소리가",
          "여기",
          "까지",
          "들려",
          "땀에",
          "젖은",
          "전화기가",
          "서도",
          "보여",
          "바로",
          "대답하는",
          "것도",
          "매력",
          "없어",
          "메시지만",
          "읽고",
          "확인",
          "안",
          "건",
          "기본",
          "어어어",
          "심했나",
          "boy",
          "이러다가",
          "지칠까",
          "걱정되긴",
          "하고",
          "그러면",
          "빠질",
          "같어",
          "답장을",
          "못해줘서",
          "어디",
          "되어줄게",
          "너의",
          "빨린",
          "성의를",
          "기다려줄게",
          "나도",
          "상처",
          "입을까",
          "걱정되지만",
          "니까",
          "이해해주길",
          "속",
          "마음",
          "들킬",
          "까봐",
          "겁이나",
          "지금처럼",
          "조금만",
          "다가와",
          "그리",
          "오래",
          "걸리진",
          "Be",
          "a",
          "man",
          "real",
          "gotta",
          "see",
          "u",
          "love",
          "me",
          "like",
          "HTTP://K2N",
          "BLOG.COM"
         ],
         "type": "scatter",
         "uid": "7af98141-b380-45eb-bcd1-4072b10c9efd",
         "x": [
          3.2843942642211914,
          -0.08432065695524216,
          1.1467056274414062,
          -0.06645619124174118,
          0.9134254455566406,
          3.629528522491455,
          -2.561256170272827,
          5.908073425292969,
          -2.115144729614258,
          1.5789579153060913,
          -0.4994804859161377,
          1.2313750982284546,
          -4.48283052444458,
          2.4921517372131348,
          -6.151211261749268,
          -3.9391188621520996,
          1.2524622678756714,
          -3.8977274894714355,
          -0.6645384430885315,
          -2.759634017944336,
          0.04935957118868828,
          -6.815982341766357,
          -4.9259257316589355,
          -3.7162160873413086,
          -0.7081528306007385,
          2.6727259159088135,
          -1.4210734367370605,
          -0.7585080862045288,
          -1.1561331748962402,
          -1.188727617263794,
          -1.5252164602279663,
          -1.0450377464294434,
          -5.087207794189453,
          1.4178651571273804,
          -1.1018697023391724,
          -0.9321070909500122,
          0.001216283766552806,
          -6.6577606201171875,
          1.70603609085083,
          4.737344264984131,
          4.443674087524414,
          2.2461323738098145,
          4.022729873657227,
          3.7931816577911377,
          -4.7885332107543945,
          -3.60207462310791,
          1.839867115020752,
          -0.96136075258255,
          -1.5697113275527954,
          -0.6952237486839294,
          2.9897537231445312,
          -2.0340497493743896,
          4.333113670349121,
          -5.716575622558594,
          2.210667848587036,
          -3.14550518989563,
          -1.862911343574524,
          -1.1013226509094238,
          1.0128589868545532,
          -5.813205242156982,
          2.4747893810272217,
          2.2592992782592773,
          -4.5043134689331055,
          6.187093257904053,
          -3.066300630569458,
          0.7383480072021484,
          0.44164907932281494,
          4.583270072937012,
          0.19813427329063416,
          -4.180800437927246,
          -0.08422200381755829,
          4.616451740264893,
          -3.9693894386291504,
          6.794101238250732,
          -2.7366719245910645,
          2.075289011001587,
          -4.886046409606934,
          -6.927717208862305,
          -6.754825592041016,
          0.25995075702667236,
          -3.143659830093384,
          -4.4027099609375,
          5.496532440185547,
          3.375701427459717,
          3.6151978969573975,
          5.872584342956543,
          -1.1930358409881592,
          -0.3472172021865845,
          -3.031874179840088,
          4.723709583282471,
          -0.786922812461853,
          1.4743850231170654,
          4.012327194213867,
          1.33798086643219,
          -0.36001506447792053,
          -0.20293834805488586,
          4.953873634338379,
          -0.2835547626018524,
          -2.284379005432129,
          5.35971736907959,
          1.4173258543014526,
          2.3153116703033447,
          3.388817310333252,
          6.462464809417725,
          -4.032694339752197,
          -1.7591689825057983,
          1.7647432088851929,
          -6.41241455078125,
          1.3199996948242188,
          -2.948493242263794,
          -3.675194025039673,
          -4.822004795074463,
          -2.647589921951294,
          -2.3195347785949707,
          -4.447526454925537,
          -1.1988506317138672,
          -2.270205020904541,
          -1.0265332460403442,
          6.579860687255859,
          3.401261329650879,
          -3.791792154312134,
          -2.375447988510132,
          -2.682671546936035,
          1.0657517910003662,
          1.918805718421936,
          0.3070368468761444,
          0.06887292861938477,
          3.445774555206299,
          0.47173020243644714,
          4.0100531578063965,
          0.40663373470306396,
          -1.8484182357788086,
          3.5288326740264893,
          0.22048437595367432,
          -1.325969934463501,
          6.320285797119141,
          -5.008300304412842,
          -2.543452262878418,
          -6.8873820304870605,
          -2.219621181488037,
          3.5342323780059814,
          -0.6348787546157837,
          2.3912887573242188,
          -1.1308211088180542,
          0.14160406589508057,
          -0.018344122916460037,
          3.3471531867980957,
          -2.5315937995910645,
          0.22272078692913055,
          3.3332724571228027,
          -4.713798999786377,
          -2.263817548751831,
          -1.8039392232894897,
          4.8490891456604,
          -0.6805822849273682,
          2.2627205848693848,
          -4.139166831970215,
          4.40133810043335,
          2.006516933441162,
          -4.882232189178467,
          0.8379563689231873,
          2.629753351211548,
          0.07517387717962265,
          2.5834507942199707
         ],
         "y": [
          2.0022146701812744,
          4.977076530456543,
          -1.9321116209030151,
          7.394322872161865,
          -2.198793411254883,
          -1.4227403402328491,
          2.899960517883301,
          -3.1824188232421875,
          1.5562595129013062,
          -1.2496427297592163,
          0.9106801748275757,
          -0.010103480890393257,
          -0.4148791432380676,
          -2.06359601020813,
          1.5385478734970093,
          -4.9121527671813965,
          -3.221203088760376,
          3.4287941455841064,
          1.1400954723358154,
          -3.9282422065734863,
          -0.36957675218582153,
          -1.232634425163269,
          3.4980199337005615,
          1.305533766746521,
          -5.163878917694092,
          -4.485682010650635,
          2.406789779663086,
          -0.6417345404624939,
          -1.4853190183639526,
          4.449216842651367,
          3.1278207302093506,
          -4.141066074371338,
          -3.2161953449249268,
          4.018503189086914,
          2.112928628921509,
          -1.0037145614624023,
          -2.620867967605591,
          2.495880603790283,
          2.7579643726348877,
          0.4698883593082428,
          -2.454916000366211,
          -3.6622698307037354,
          -0.4233478605747223,
          -3.6516666412353516,
          1.9970613718032837,
          -4.586590766906738,
          0.9313449859619141,
          6.392947673797607,
          0.37095221877098083,
          -2.5660014152526855,
          -5.959283828735352,
          -0.8248840570449829,
          -4.747068881988525,
          -0.555409848690033,
          1.622501254081726,
          0.15163661539554596,
          3.333684206008911,
          -3.9672915935516357,
          -5.109771728515625,
          4.6182942390441895,
          0.5462542176246643,
          5.575192928314209,
          -1.3962790966033936,
          1.2676174640655518,
          2.4307639598846436,
          -3.09930157661438,
          -1.6849263906478882,
          4.210484981536865,
          -1.6208257675170898,
          1.7003092765808105,
          7.095028400421143,
          0.9329404830932617,
          -2.776298999786377,
          -1.191831111907959,
          4.968535423278809,
          3.0709664821624756,
          -4.879321575164795,
          -1.7183159589767456,
          1.242048978805542,
          -4.358980178833008,
          -0.9309134483337402,
          0.2521001696586609,
          1.141287922859192,
          -1.6718952655792236,
          -2.512772798538208,
          -0.7732356786727905,
          6.363447666168213,
          -3.1911065578460693,
          5.45986270904541,
          5.36452054977417,
          -6.05596923828125,
          -5.0200700759887695,
          4.4366865158081055,
          1.9003441333770752,
          3.164820432662964,
          0.944977343082428,
          2.081714391708374,
          2.215468645095825,
          -2.6368112564086914,
          3.8582210540771484,
          4.1542768478393555,
          3.224656581878662,
          0.7110751867294312,
          2.982638359069824,
          5.77935791015625,
          -1.3917590379714966,
          -1.2790309190750122,
          1.5159671306610107,
          1.4448424577713013,
          0.5884144306182861,
          3.6163337230682373,
          -2.923247814178467,
          -1.4344379901885986,
          -6.1419291496276855,
          3.2050905227661133,
          -3.052110433578491,
          -4.722005367279053,
          -0.32919827103614807,
          3.0030088424682617,
          -3.2720608711242676,
          5.795146465301514,
          -2.8332295417785645,
          -3.7998812198638916,
          -0.01579529047012329,
          5.945755958557129,
          4.0384016036987305,
          1.5768104791641235,
          4.607840061187744,
          -6.9695000648498535,
          -0.2035817950963974,
          5.575191974639893,
          1.1375705003738403,
          1.749018669128418,
          -4.525435924530029,
          3.8977839946746826,
          -0.966293215751648,
          -1.3502557277679443,
          0.3358359932899475,
          -1.1854537725448608,
          1.6230028867721558,
          2.767143487930298,
          3.412919044494629,
          -0.474033385515213,
          6.5069780349731445,
          0.8903042674064636,
          -0.3055988550186157,
          1.94746732711792,
          4.805919647216797,
          2.9054946899414062,
          7.249308109283447,
          4.45701789855957,
          -0.5788260698318481,
          -1.9659279584884644,
          4.064468860626221,
          -5.132839202880859,
          -3.410956621170044,
          -2.504456043243408,
          2.402381658554077,
          5.84982967376709,
          2.4252846240997314,
          1.9888310432434082,
          0.403072327375412,
          2.175966739654541,
          -0.39607924222946167
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"dcfbb031-00b6-4392-b66e-ec8c49e39223\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"dcfbb031-00b6-4392-b66e-ec8c49e39223\")) {\n",
       "    Plotly.newPlot(\"dcfbb031-00b6-4392-b66e-ec8c49e39223\", [{\"mode\": \"text\", \"text\": [\"CHEER\", \"UP\", \"\\ub9e4\\uc77c\", \"\\uc6b8\\ub9ac\\ub294\", \"\\ubca8\\ubca8\\ubca8\", \"\\uc774\\uc820\", \"\\ub098\\ub97c\", \"\\ubc30\\ub824\", \"\\ud574\\uc918\", \"\\ubc30\\ud130\\ub9ac\", \"\\ub0ad\\ube44\\ud558\\uae34\", \"\\uc2eb\\uc5b4\", \"\\uc790\\uafb8\", \"\\ub9cc\", \"\\ubd10\", \"\\uc640\", \"\\uc804\\ud654\\uac00\", \"\\ud391\", \"\\ud130\\uc9c8\", \"\\uac83\\ub9cc\", \"\\uac19\\uc544\", \"\\ubab0\\ub77c\", \"\\uc228\\ub3c4\", \"\\ubabb\", \"\\uc270\\ub300\", \"\\ub098\", \"\\ub54c\\ubb38\\uc5d0\", \"\\ud798\\ub4e4\\uc5b4\", \"\\ucff5\", \"\\uc2ec\\uc7a5\\uc774\", \"\\ub5a8\\uc5b4\\uc9c4\\ub300\", \"\\uc65c\", \"\\uac54\", \"\\ub9d0\\uc740\", \"\\ub108\\ubb34\", \"\\uc608\\uc058\\ub300\", \"\\uc790\\ub791\", \"\\ud558\\ub294\\uac74\", \"\\uc544\\ub2c8\\uad6c\", \"\\uc544\", \"\\uc544\\uae4c\\ub294\", \"\\ubc1b\\uc544\\uc11c\", \"\\ubbf8\\uc548\\ud574\", \"\\uce5c\\uad6c\\ub97c\", \"\\ub9cc\\ub098\\ub290\\ub77c\", \"shy\", \"\\ub9cc\\ub098\\uae34\", \"\\uc880\", \"\\uadf8\\ub807\\uad6c\", \"\\uc788\\ub2e4\", \"\\uc5f0\\ub77d\\ud560\\uac8c\", \"later\", \"\\uc870\\ub974\\uc9c0\\ub9c8\", \"\\uc5bc\\ub9c8\", \"\\uac00\\uc9c0\", \"\\uc54a\\uc544\", \"\\ubd80\\ub974\\uac8c\", \"\\ud574\\uc904\\uac8c\", \"Baby\", \"\\uc544\\uc9c1\\uc740\", \"\\uc77c\\ub7ec\", \"\\ub0b4\", \"\\ub9d8\", \"\\uac19\\uae34\", \"\\ud558\\uc9c0\\ub9cc\", \"\\ub354\", \"\\ubcf4\\uc5ec\\uc904\\ub798\", \"BABY\", \"\\ud798\\uc744\", \"\\uc5ec\\uc790\", \"\\uac00\", \"\\uc27d\\uac8c\", \"\\ub9d8\\uc744\", \"\\uc8fc\\uba74\", \"\\uc548\\ub3fc\", \"\\uadf8\\ub798\\uc57c\", \"\\ub2c8\\uac00\", \"\\ub0a0\", \"\\uc88b\\uc544\", \"\\ud558\\uac8c\", \"\\ub420\\uac78\", \"\\ud0dc\\uc5f0\\ud558\\uac8c\", \"\\uc5f0\\uae30\\ud560\\ub798\", \"\\uc544\\ubb34\\ub807\\uc9c0\", \"\\uc54a\\uac8c\", \"\\ub0b4\\uac00\", \"\\ub110\", \"\\ud558\\ub294\", \"\\ubaa8\\ub974\\uac8c\", \"just\", \"get\", \"it\", \"together\", \"and\", \"then\", \"baby\", \"\\uc548\\uc808\\ubd80\\uc808\", \"\\ubaa9\\uc18c\\ub9ac\\uac00\", \"\\uc5ec\\uae30\", \"\\uae4c\\uc9c0\", \"\\ub4e4\\ub824\", \"\\ub540\\uc5d0\", \"\\uc816\\uc740\", \"\\uc804\\ud654\\uae30\\uac00\", \"\\uc11c\\ub3c4\", \"\\ubcf4\\uc5ec\", \"\\ubc14\\ub85c\", \"\\ub300\\ub2f5\\ud558\\ub294\", \"\\uac83\\ub3c4\", \"\\ub9e4\\ub825\", \"\\uc5c6\\uc5b4\", \"\\uba54\\uc2dc\\uc9c0\\ub9cc\", \"\\uc77d\\uace0\", \"\\ud655\\uc778\", \"\\uc548\", \"\\uac74\", \"\\uae30\\ubcf8\", \"\\uc5b4\\uc5b4\\uc5b4\", \"\\uc2ec\\ud588\\ub098\", \"boy\", \"\\uc774\\ub7ec\\ub2e4\\uac00\", \"\\uc9c0\\uce60\\uae4c\", \"\\uac71\\uc815\\ub418\\uae34\", \"\\ud558\\uace0\", \"\\uadf8\\ub7ec\\uba74\", \"\\ube60\\uc9c8\", \"\\uac19\\uc5b4\", \"\\ub2f5\\uc7a5\\uc744\", \"\\ubabb\\ud574\\uc918\\uc11c\", \"\\uc5b4\\ub514\", \"\\ub418\\uc5b4\\uc904\\uac8c\", \"\\ub108\\uc758\", \"\\ube68\\ub9b0\", \"\\uc131\\uc758\\ub97c\", \"\\uae30\\ub2e4\\ub824\\uc904\\uac8c\", \"\\ub098\\ub3c4\", \"\\uc0c1\\ucc98\", \"\\uc785\\uc744\\uae4c\", \"\\uac71\\uc815\\ub418\\uc9c0\\ub9cc\", \"\\ub2c8\\uae4c\", \"\\uc774\\ud574\\ud574\\uc8fc\\uae38\", \"\\uc18d\", \"\\ub9c8\\uc74c\", \"\\ub4e4\\ud0ac\", \"\\uae4c\\ubd10\", \"\\uac81\\uc774\\ub098\", \"\\uc9c0\\uae08\\ucc98\\ub7fc\", \"\\uc870\\uae08\\ub9cc\", \"\\ub2e4\\uac00\\uc640\", \"\\uadf8\\ub9ac\", \"\\uc624\\ub798\", \"\\uac78\\ub9ac\\uc9c4\", \"Be\", \"a\", \"man\", \"real\", \"gotta\", \"see\", \"u\", \"love\", \"me\", \"like\", \"HTTP://K2N\", \"BLOG.COM\"], \"x\": [3.2843942642211914, -0.08432065695524216, 1.1467056274414062, -0.06645619124174118, 0.9134254455566406, 3.629528522491455, -2.561256170272827, 5.908073425292969, -2.115144729614258, 1.5789579153060913, -0.4994804859161377, 1.2313750982284546, -4.48283052444458, 2.4921517372131348, -6.151211261749268, -3.9391188621520996, 1.2524622678756714, -3.8977274894714355, -0.6645384430885315, -2.759634017944336, 0.04935957118868828, -6.815982341766357, -4.9259257316589355, -3.7162160873413086, -0.7081528306007385, 2.6727259159088135, -1.4210734367370605, -0.7585080862045288, -1.1561331748962402, -1.188727617263794, -1.5252164602279663, -1.0450377464294434, -5.087207794189453, 1.4178651571273804, -1.1018697023391724, -0.9321070909500122, 0.001216283766552806, -6.6577606201171875, 1.70603609085083, 4.737344264984131, 4.443674087524414, 2.2461323738098145, 4.022729873657227, 3.7931816577911377, -4.7885332107543945, -3.60207462310791, 1.839867115020752, -0.96136075258255, -1.5697113275527954, -0.6952237486839294, 2.9897537231445312, -2.0340497493743896, 4.333113670349121, -5.716575622558594, 2.210667848587036, -3.14550518989563, -1.862911343574524, -1.1013226509094238, 1.0128589868545532, -5.813205242156982, 2.4747893810272217, 2.2592992782592773, -4.5043134689331055, 6.187093257904053, -3.066300630569458, 0.7383480072021484, 0.44164907932281494, 4.583270072937012, 0.19813427329063416, -4.180800437927246, -0.08422200381755829, 4.616451740264893, -3.9693894386291504, 6.794101238250732, -2.7366719245910645, 2.075289011001587, -4.886046409606934, -6.927717208862305, -6.754825592041016, 0.25995075702667236, -3.143659830093384, -4.4027099609375, 5.496532440185547, 3.375701427459717, 3.6151978969573975, 5.872584342956543, -1.1930358409881592, -0.3472172021865845, -3.031874179840088, 4.723709583282471, -0.786922812461853, 1.4743850231170654, 4.012327194213867, 1.33798086643219, -0.36001506447792053, -0.20293834805488586, 4.953873634338379, -0.2835547626018524, -2.284379005432129, 5.35971736907959, 1.4173258543014526, 2.3153116703033447, 3.388817310333252, 6.462464809417725, -4.032694339752197, -1.7591689825057983, 1.7647432088851929, -6.41241455078125, 1.3199996948242188, -2.948493242263794, -3.675194025039673, -4.822004795074463, -2.647589921951294, -2.3195347785949707, -4.447526454925537, -1.1988506317138672, -2.270205020904541, -1.0265332460403442, 6.579860687255859, 3.401261329650879, -3.791792154312134, -2.375447988510132, -2.682671546936035, 1.0657517910003662, 1.918805718421936, 0.3070368468761444, 0.06887292861938477, 3.445774555206299, 0.47173020243644714, 4.0100531578063965, 0.40663373470306396, -1.8484182357788086, 3.5288326740264893, 0.22048437595367432, -1.325969934463501, 6.320285797119141, -5.008300304412842, -2.543452262878418, -6.8873820304870605, -2.219621181488037, 3.5342323780059814, -0.6348787546157837, 2.3912887573242188, -1.1308211088180542, 0.14160406589508057, -0.018344122916460037, 3.3471531867980957, -2.5315937995910645, 0.22272078692913055, 3.3332724571228027, -4.713798999786377, -2.263817548751831, -1.8039392232894897, 4.8490891456604, -0.6805822849273682, 2.2627205848693848, -4.139166831970215, 4.40133810043335, 2.006516933441162, -4.882232189178467, 0.8379563689231873, 2.629753351211548, 0.07517387717962265, 2.5834507942199707], \"y\": [2.0022146701812744, 4.977076530456543, -1.9321116209030151, 7.394322872161865, -2.198793411254883, -1.4227403402328491, 2.899960517883301, -3.1824188232421875, 1.5562595129013062, -1.2496427297592163, 0.9106801748275757, -0.010103480890393257, -0.4148791432380676, -2.06359601020813, 1.5385478734970093, -4.9121527671813965, -3.221203088760376, 3.4287941455841064, 1.1400954723358154, -3.9282422065734863, -0.36957675218582153, -1.232634425163269, 3.4980199337005615, 1.305533766746521, -5.163878917694092, -4.485682010650635, 2.406789779663086, -0.6417345404624939, -1.4853190183639526, 4.449216842651367, 3.1278207302093506, -4.141066074371338, -3.2161953449249268, 4.018503189086914, 2.112928628921509, -1.0037145614624023, -2.620867967605591, 2.495880603790283, 2.7579643726348877, 0.4698883593082428, -2.454916000366211, -3.6622698307037354, -0.4233478605747223, -3.6516666412353516, 1.9970613718032837, -4.586590766906738, 0.9313449859619141, 6.392947673797607, 0.37095221877098083, -2.5660014152526855, -5.959283828735352, -0.8248840570449829, -4.747068881988525, -0.555409848690033, 1.622501254081726, 0.15163661539554596, 3.333684206008911, -3.9672915935516357, -5.109771728515625, 4.6182942390441895, 0.5462542176246643, 5.575192928314209, -1.3962790966033936, 1.2676174640655518, 2.4307639598846436, -3.09930157661438, -1.6849263906478882, 4.210484981536865, -1.6208257675170898, 1.7003092765808105, 7.095028400421143, 0.9329404830932617, -2.776298999786377, -1.191831111907959, 4.968535423278809, 3.0709664821624756, -4.879321575164795, -1.7183159589767456, 1.242048978805542, -4.358980178833008, -0.9309134483337402, 0.2521001696586609, 1.141287922859192, -1.6718952655792236, -2.512772798538208, -0.7732356786727905, 6.363447666168213, -3.1911065578460693, 5.45986270904541, 5.36452054977417, -6.05596923828125, -5.0200700759887695, 4.4366865158081055, 1.9003441333770752, 3.164820432662964, 0.944977343082428, 2.081714391708374, 2.215468645095825, -2.6368112564086914, 3.8582210540771484, 4.1542768478393555, 3.224656581878662, 0.7110751867294312, 2.982638359069824, 5.77935791015625, -1.3917590379714966, -1.2790309190750122, 1.5159671306610107, 1.4448424577713013, 0.5884144306182861, 3.6163337230682373, -2.923247814178467, -1.4344379901885986, -6.1419291496276855, 3.2050905227661133, -3.052110433578491, -4.722005367279053, -0.32919827103614807, 3.0030088424682617, -3.2720608711242676, 5.795146465301514, -2.8332295417785645, -3.7998812198638916, -0.01579529047012329, 5.945755958557129, 4.0384016036987305, 1.5768104791641235, 4.607840061187744, -6.9695000648498535, -0.2035817950963974, 5.575191974639893, 1.1375705003738403, 1.749018669128418, -4.525435924530029, 3.8977839946746826, -0.966293215751648, -1.3502557277679443, 0.3358359932899475, -1.1854537725448608, 1.6230028867721558, 2.767143487930298, 3.412919044494629, -0.474033385515213, 6.5069780349731445, 0.8903042674064636, -0.3055988550186157, 1.94746732711792, 4.805919647216797, 2.9054946899414062, 7.249308109283447, 4.45701789855957, -0.5788260698318481, -1.9659279584884644, 4.064468860626221, -5.132839202880859, -3.410956621170044, -2.504456043243408, 2.402381658554077, 5.84982967376709, 2.4252846240997314, 1.9888310432434082, 0.403072327375412, 2.175966739654541, -0.39607924222946167], \"type\": \"scatter\", \"uid\": \"caf6f4bb-108e-45aa-8f24-1cf716103a63\"}], {}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"dcfbb031-00b6-4392-b66e-ec8c49e39223\")) {window._Plotly.Plots.resize(document.getElementById(\"dcfbb031-00b6-4392-b66e-ec8c49e39223\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"dcfbb031-00b6-4392-b66e-ec8c49e39223\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"dcfbb031-00b6-4392-b66e-ec8c49e39223\")) {\n",
       "    Plotly.newPlot(\"dcfbb031-00b6-4392-b66e-ec8c49e39223\", [{\"mode\": \"text\", \"text\": [\"CHEER\", \"UP\", \"\\ub9e4\\uc77c\", \"\\uc6b8\\ub9ac\\ub294\", \"\\ubca8\\ubca8\\ubca8\", \"\\uc774\\uc820\", \"\\ub098\\ub97c\", \"\\ubc30\\ub824\", \"\\ud574\\uc918\", \"\\ubc30\\ud130\\ub9ac\", \"\\ub0ad\\ube44\\ud558\\uae34\", \"\\uc2eb\\uc5b4\", \"\\uc790\\uafb8\", \"\\ub9cc\", \"\\ubd10\", \"\\uc640\", \"\\uc804\\ud654\\uac00\", \"\\ud391\", \"\\ud130\\uc9c8\", \"\\uac83\\ub9cc\", \"\\uac19\\uc544\", \"\\ubab0\\ub77c\", \"\\uc228\\ub3c4\", \"\\ubabb\", \"\\uc270\\ub300\", \"\\ub098\", \"\\ub54c\\ubb38\\uc5d0\", \"\\ud798\\ub4e4\\uc5b4\", \"\\ucff5\", \"\\uc2ec\\uc7a5\\uc774\", \"\\ub5a8\\uc5b4\\uc9c4\\ub300\", \"\\uc65c\", \"\\uac54\", \"\\ub9d0\\uc740\", \"\\ub108\\ubb34\", \"\\uc608\\uc058\\ub300\", \"\\uc790\\ub791\", \"\\ud558\\ub294\\uac74\", \"\\uc544\\ub2c8\\uad6c\", \"\\uc544\", \"\\uc544\\uae4c\\ub294\", \"\\ubc1b\\uc544\\uc11c\", \"\\ubbf8\\uc548\\ud574\", \"\\uce5c\\uad6c\\ub97c\", \"\\ub9cc\\ub098\\ub290\\ub77c\", \"shy\", \"\\ub9cc\\ub098\\uae34\", \"\\uc880\", \"\\uadf8\\ub807\\uad6c\", \"\\uc788\\ub2e4\", \"\\uc5f0\\ub77d\\ud560\\uac8c\", \"later\", \"\\uc870\\ub974\\uc9c0\\ub9c8\", \"\\uc5bc\\ub9c8\", \"\\uac00\\uc9c0\", \"\\uc54a\\uc544\", \"\\ubd80\\ub974\\uac8c\", \"\\ud574\\uc904\\uac8c\", \"Baby\", \"\\uc544\\uc9c1\\uc740\", \"\\uc77c\\ub7ec\", \"\\ub0b4\", \"\\ub9d8\", \"\\uac19\\uae34\", \"\\ud558\\uc9c0\\ub9cc\", \"\\ub354\", \"\\ubcf4\\uc5ec\\uc904\\ub798\", \"BABY\", \"\\ud798\\uc744\", \"\\uc5ec\\uc790\", \"\\uac00\", \"\\uc27d\\uac8c\", \"\\ub9d8\\uc744\", \"\\uc8fc\\uba74\", \"\\uc548\\ub3fc\", \"\\uadf8\\ub798\\uc57c\", \"\\ub2c8\\uac00\", \"\\ub0a0\", \"\\uc88b\\uc544\", \"\\ud558\\uac8c\", \"\\ub420\\uac78\", \"\\ud0dc\\uc5f0\\ud558\\uac8c\", \"\\uc5f0\\uae30\\ud560\\ub798\", \"\\uc544\\ubb34\\ub807\\uc9c0\", \"\\uc54a\\uac8c\", \"\\ub0b4\\uac00\", \"\\ub110\", \"\\ud558\\ub294\", \"\\ubaa8\\ub974\\uac8c\", \"just\", \"get\", \"it\", \"together\", \"and\", \"then\", \"baby\", \"\\uc548\\uc808\\ubd80\\uc808\", \"\\ubaa9\\uc18c\\ub9ac\\uac00\", \"\\uc5ec\\uae30\", \"\\uae4c\\uc9c0\", \"\\ub4e4\\ub824\", \"\\ub540\\uc5d0\", \"\\uc816\\uc740\", \"\\uc804\\ud654\\uae30\\uac00\", \"\\uc11c\\ub3c4\", \"\\ubcf4\\uc5ec\", \"\\ubc14\\ub85c\", \"\\ub300\\ub2f5\\ud558\\ub294\", \"\\uac83\\ub3c4\", \"\\ub9e4\\ub825\", \"\\uc5c6\\uc5b4\", \"\\uba54\\uc2dc\\uc9c0\\ub9cc\", \"\\uc77d\\uace0\", \"\\ud655\\uc778\", \"\\uc548\", \"\\uac74\", \"\\uae30\\ubcf8\", \"\\uc5b4\\uc5b4\\uc5b4\", \"\\uc2ec\\ud588\\ub098\", \"boy\", \"\\uc774\\ub7ec\\ub2e4\\uac00\", \"\\uc9c0\\uce60\\uae4c\", \"\\uac71\\uc815\\ub418\\uae34\", \"\\ud558\\uace0\", \"\\uadf8\\ub7ec\\uba74\", \"\\ube60\\uc9c8\", \"\\uac19\\uc5b4\", \"\\ub2f5\\uc7a5\\uc744\", \"\\ubabb\\ud574\\uc918\\uc11c\", \"\\uc5b4\\ub514\", \"\\ub418\\uc5b4\\uc904\\uac8c\", \"\\ub108\\uc758\", \"\\ube68\\ub9b0\", \"\\uc131\\uc758\\ub97c\", \"\\uae30\\ub2e4\\ub824\\uc904\\uac8c\", \"\\ub098\\ub3c4\", \"\\uc0c1\\ucc98\", \"\\uc785\\uc744\\uae4c\", \"\\uac71\\uc815\\ub418\\uc9c0\\ub9cc\", \"\\ub2c8\\uae4c\", \"\\uc774\\ud574\\ud574\\uc8fc\\uae38\", \"\\uc18d\", \"\\ub9c8\\uc74c\", \"\\ub4e4\\ud0ac\", \"\\uae4c\\ubd10\", \"\\uac81\\uc774\\ub098\", \"\\uc9c0\\uae08\\ucc98\\ub7fc\", \"\\uc870\\uae08\\ub9cc\", \"\\ub2e4\\uac00\\uc640\", \"\\uadf8\\ub9ac\", \"\\uc624\\ub798\", \"\\uac78\\ub9ac\\uc9c4\", \"Be\", \"a\", \"man\", \"real\", \"gotta\", \"see\", \"u\", \"love\", \"me\", \"like\", \"HTTP://K2N\", \"BLOG.COM\"], \"x\": [3.2843942642211914, -0.08432065695524216, 1.1467056274414062, -0.06645619124174118, 0.9134254455566406, 3.629528522491455, -2.561256170272827, 5.908073425292969, -2.115144729614258, 1.5789579153060913, -0.4994804859161377, 1.2313750982284546, -4.48283052444458, 2.4921517372131348, -6.151211261749268, -3.9391188621520996, 1.2524622678756714, -3.8977274894714355, -0.6645384430885315, -2.759634017944336, 0.04935957118868828, -6.815982341766357, -4.9259257316589355, -3.7162160873413086, -0.7081528306007385, 2.6727259159088135, -1.4210734367370605, -0.7585080862045288, -1.1561331748962402, -1.188727617263794, -1.5252164602279663, -1.0450377464294434, -5.087207794189453, 1.4178651571273804, -1.1018697023391724, -0.9321070909500122, 0.001216283766552806, -6.6577606201171875, 1.70603609085083, 4.737344264984131, 4.443674087524414, 2.2461323738098145, 4.022729873657227, 3.7931816577911377, -4.7885332107543945, -3.60207462310791, 1.839867115020752, -0.96136075258255, -1.5697113275527954, -0.6952237486839294, 2.9897537231445312, -2.0340497493743896, 4.333113670349121, -5.716575622558594, 2.210667848587036, -3.14550518989563, -1.862911343574524, -1.1013226509094238, 1.0128589868545532, -5.813205242156982, 2.4747893810272217, 2.2592992782592773, -4.5043134689331055, 6.187093257904053, -3.066300630569458, 0.7383480072021484, 0.44164907932281494, 4.583270072937012, 0.19813427329063416, -4.180800437927246, -0.08422200381755829, 4.616451740264893, -3.9693894386291504, 6.794101238250732, -2.7366719245910645, 2.075289011001587, -4.886046409606934, -6.927717208862305, -6.754825592041016, 0.25995075702667236, -3.143659830093384, -4.4027099609375, 5.496532440185547, 3.375701427459717, 3.6151978969573975, 5.872584342956543, -1.1930358409881592, -0.3472172021865845, -3.031874179840088, 4.723709583282471, -0.786922812461853, 1.4743850231170654, 4.012327194213867, 1.33798086643219, -0.36001506447792053, -0.20293834805488586, 4.953873634338379, -0.2835547626018524, -2.284379005432129, 5.35971736907959, 1.4173258543014526, 2.3153116703033447, 3.388817310333252, 6.462464809417725, -4.032694339752197, -1.7591689825057983, 1.7647432088851929, -6.41241455078125, 1.3199996948242188, -2.948493242263794, -3.675194025039673, -4.822004795074463, -2.647589921951294, -2.3195347785949707, -4.447526454925537, -1.1988506317138672, -2.270205020904541, -1.0265332460403442, 6.579860687255859, 3.401261329650879, -3.791792154312134, -2.375447988510132, -2.682671546936035, 1.0657517910003662, 1.918805718421936, 0.3070368468761444, 0.06887292861938477, 3.445774555206299, 0.47173020243644714, 4.0100531578063965, 0.40663373470306396, -1.8484182357788086, 3.5288326740264893, 0.22048437595367432, -1.325969934463501, 6.320285797119141, -5.008300304412842, -2.543452262878418, -6.8873820304870605, -2.219621181488037, 3.5342323780059814, -0.6348787546157837, 2.3912887573242188, -1.1308211088180542, 0.14160406589508057, -0.018344122916460037, 3.3471531867980957, -2.5315937995910645, 0.22272078692913055, 3.3332724571228027, -4.713798999786377, -2.263817548751831, -1.8039392232894897, 4.8490891456604, -0.6805822849273682, 2.2627205848693848, -4.139166831970215, 4.40133810043335, 2.006516933441162, -4.882232189178467, 0.8379563689231873, 2.629753351211548, 0.07517387717962265, 2.5834507942199707], \"y\": [2.0022146701812744, 4.977076530456543, -1.9321116209030151, 7.394322872161865, -2.198793411254883, -1.4227403402328491, 2.899960517883301, -3.1824188232421875, 1.5562595129013062, -1.2496427297592163, 0.9106801748275757, -0.010103480890393257, -0.4148791432380676, -2.06359601020813, 1.5385478734970093, -4.9121527671813965, -3.221203088760376, 3.4287941455841064, 1.1400954723358154, -3.9282422065734863, -0.36957675218582153, -1.232634425163269, 3.4980199337005615, 1.305533766746521, -5.163878917694092, -4.485682010650635, 2.406789779663086, -0.6417345404624939, -1.4853190183639526, 4.449216842651367, 3.1278207302093506, -4.141066074371338, -3.2161953449249268, 4.018503189086914, 2.112928628921509, -1.0037145614624023, -2.620867967605591, 2.495880603790283, 2.7579643726348877, 0.4698883593082428, -2.454916000366211, -3.6622698307037354, -0.4233478605747223, -3.6516666412353516, 1.9970613718032837, -4.586590766906738, 0.9313449859619141, 6.392947673797607, 0.37095221877098083, -2.5660014152526855, -5.959283828735352, -0.8248840570449829, -4.747068881988525, -0.555409848690033, 1.622501254081726, 0.15163661539554596, 3.333684206008911, -3.9672915935516357, -5.109771728515625, 4.6182942390441895, 0.5462542176246643, 5.575192928314209, -1.3962790966033936, 1.2676174640655518, 2.4307639598846436, -3.09930157661438, -1.6849263906478882, 4.210484981536865, -1.6208257675170898, 1.7003092765808105, 7.095028400421143, 0.9329404830932617, -2.776298999786377, -1.191831111907959, 4.968535423278809, 3.0709664821624756, -4.879321575164795, -1.7183159589767456, 1.242048978805542, -4.358980178833008, -0.9309134483337402, 0.2521001696586609, 1.141287922859192, -1.6718952655792236, -2.512772798538208, -0.7732356786727905, 6.363447666168213, -3.1911065578460693, 5.45986270904541, 5.36452054977417, -6.05596923828125, -5.0200700759887695, 4.4366865158081055, 1.9003441333770752, 3.164820432662964, 0.944977343082428, 2.081714391708374, 2.215468645095825, -2.6368112564086914, 3.8582210540771484, 4.1542768478393555, 3.224656581878662, 0.7110751867294312, 2.982638359069824, 5.77935791015625, -1.3917590379714966, -1.2790309190750122, 1.5159671306610107, 1.4448424577713013, 0.5884144306182861, 3.6163337230682373, -2.923247814178467, -1.4344379901885986, -6.1419291496276855, 3.2050905227661133, -3.052110433578491, -4.722005367279053, -0.32919827103614807, 3.0030088424682617, -3.2720608711242676, 5.795146465301514, -2.8332295417785645, -3.7998812198638916, -0.01579529047012329, 5.945755958557129, 4.0384016036987305, 1.5768104791641235, 4.607840061187744, -6.9695000648498535, -0.2035817950963974, 5.575191974639893, 1.1375705003738403, 1.749018669128418, -4.525435924530029, 3.8977839946746826, -0.966293215751648, -1.3502557277679443, 0.3358359932899475, -1.1854537725448608, 1.6230028867721558, 2.767143487930298, 3.412919044494629, -0.474033385515213, 6.5069780349731445, 0.8903042674064636, -0.3055988550186157, 1.94746732711792, 4.805919647216797, 2.9054946899414062, 7.249308109283447, 4.45701789855957, -0.5788260698318481, -1.9659279584884644, 4.064468860626221, -5.132839202880859, -3.410956621170044, -2.504456043243408, 2.402381658554077, 5.84982967376709, 2.4252846240997314, 1.9888310432434082, 0.403072327375412, 2.175966739654541, -0.39607924222946167], \"type\": \"scatter\", \"uid\": \"caf6f4bb-108e-45aa-8f24-1cf716103a63\"}], {}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"dcfbb031-00b6-4392-b66e-ec8c49e39223\")) {window._Plotly.Plots.resize(document.getElementById(\"dcfbb031-00b6-4392-b66e-ec8c49e39223\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 한국어 예시\n",
    "reduce_dimensions(w2v_ko)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_en = [[\"my\", \"name\", \"is\", \"jamie\"], [\"jamie\", \"is\", \"cute\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moodern/anaconda3/envs/deepnlp/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "\n",
      "2019-04-23 09:58:10,864 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'jamia' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-4dc7e329baaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jamia\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/deepnlp/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1396\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 )\n\u001b[0;32m-> 1398\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepnlp/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0mRefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWordEmbeddingsKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \"\"\"\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method will be removed in 4.0.0, use self.wv.wmdistance() instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepnlp/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepnlp/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'jamia' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "# 워드투벡은 학습시 없었던 단어에 대해서는 계산해주지 못한다.\n",
    "w2v_en.most_similar(\"jamia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "ft_en = FastText(size=4, window=3, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-23 09:53:50,084 : INFO : collecting all words and their counts\n",
      "2019-04-23 09:53:50,085 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-04-23 09:53:50,086 : INFO : collected 5 word types from a corpus of 7 raw words and 2 sentences\n",
      "2019-04-23 09:53:50,087 : INFO : Loading a fresh vocabulary\n",
      "2019-04-23 09:53:50,087 : INFO : min_count=1 retains 5 unique words (100% of original 5, drops 0)\n",
      "2019-04-23 09:53:50,088 : INFO : min_count=1 leaves 7 word corpus (100% of original 7, drops 0)\n",
      "2019-04-23 09:53:50,089 : INFO : deleting the raw counts dictionary of 5 items\n",
      "2019-04-23 09:53:50,090 : INFO : sample=0.001 downsamples 5 most-common words\n",
      "2019-04-23 09:53:50,090 : INFO : downsampling leaves estimated 0 word corpus (7.5% of prior 7)\n",
      "2019-04-23 09:53:50,092 : INFO : estimated required memory for 5 words, 40 buckets and 4 dimensions: 3860 bytes\n",
      "2019-04-23 09:53:50,093 : INFO : resetting layer weights\n",
      "2019-04-23 09:53:50,106 : INFO : Total number of ngrams is 40\n"
     ]
    }
   ],
   "source": [
    "ft_en.build_vocab(documents_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-23 09:54:31,424 : INFO : training model with 3 workers on 5 vocabulary and 4 features, using sg=0 hs=0 sample=0.001 negative=5 window=3\n",
      "2019-04-23 09:54:31,426 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 09:54:31,427 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 09:54:31,427 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 09:54:31,428 : INFO : EPOCH - 1 : training on 7 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-04-23 09:54:31,431 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 09:54:31,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 09:54:31,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 09:54:31,433 : INFO : EPOCH - 2 : training on 7 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-04-23 09:54:31,436 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 09:54:31,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 09:54:31,438 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 09:54:31,439 : INFO : EPOCH - 3 : training on 7 raw words (1 effective words) took 0.0s, 352 effective words/s\n",
      "2019-04-23 09:54:31,441 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 09:54:31,442 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 09:54:31,443 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 09:54:31,443 : INFO : EPOCH - 4 : training on 7 raw words (1 effective words) took 0.0s, 416 effective words/s\n",
      "2019-04-23 09:54:31,446 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 09:54:31,447 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 09:54:31,447 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 09:54:31,448 : INFO : EPOCH - 5 : training on 7 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-04-23 09:54:31,450 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 09:54:31,451 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 09:54:31,452 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 09:54:31,453 : INFO : EPOCH - 6 : training on 7 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-04-23 09:54:31,456 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 09:54:31,456 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 09:54:31,457 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 09:54:31,458 : INFO : EPOCH - 7 : training on 7 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-04-23 09:54:31,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 09:54:31,462 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 09:54:31,463 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 09:54:31,463 : INFO : EPOCH - 8 : training on 7 raw words (1 effective words) took 0.0s, 317 effective words/s\n",
      "2019-04-23 09:54:31,466 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 09:54:31,467 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 09:54:31,468 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 09:54:31,468 : INFO : EPOCH - 9 : training on 7 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-04-23 09:54:31,471 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-23 09:54:31,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-23 09:54:31,473 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-23 09:54:31,474 : INFO : EPOCH - 10 : training on 7 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-04-23 09:54:31,476 : INFO : training on a 70 raw words (3 effective words) took 0.1s, 59 effective words/s\n",
      "2019-04-23 09:54:31,477 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "ft_en.train(sentences=documents_en, total_examples=len(documents_en), epochs=10)  # train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('my', 0.8944276571273804),\n",
       " ('jamie', 0.7871583104133606),\n",
       " ('name', 0.3816155791282654),\n",
       " ('is', 0.3451642394065857),\n",
       " ('cute', 0.30520403385162354)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FastText는 학습시 없었던 단어에 대해서도 계산해준다.\n",
    "ft_en.wv.most_similar(\"jamia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Embeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료 \n",
    "* Applied Text Analysis with Python: Enabling Language-Aware Data Products with Machine Learning - https://www.amazon.com/Applied-Text-Analysis-Python-Language-Aware/dp/1491963042/\n",
    "* Natural Language Processing - https://www.coursera.org/learn/language-processing / Main approaches in NLP\n",
    "* http://git.ajou.ac.kr/open-source-2018-spring/python_Korean_NLP/blob/master/README.md\n",
    "* https://github.com/lovit/soynlp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
